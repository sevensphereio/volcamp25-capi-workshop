#!/bin/bash

set -e

echo "ğŸ§¹ ClusterAPI Workshop Cleanup"
echo "=============================="
echo ""

# Check if any workload clusters exist
CLUSTERS=$(kubectl get clusters --no-headers -o custom-columns=NAME:.metadata.name 2>/dev/null | grep -v "capi-management" || echo "")

if [ -z "$CLUSTERS" ]; then
    echo "âœ… Aucun workload cluster Ã  nettoyer"
    echo ""
    echo "Ã‰tat actuel:"
    kubectl get clusters,machines 2>/dev/null || echo "Aucune ressource ClusterAPI trouvÃ©e"
    exit 0
fi

echo "ğŸ” Workload clusters trouvÃ©s:"
for cluster in $CLUSTERS; do
    echo "   - $cluster"
done
echo ""

# Warn user
echo "âš ï¸  ATTENTION: Cette opÃ©ration va supprimer TOUS les workload clusters!"
echo ""
echo "Clusters qui seront supprimÃ©s:"
echo "$CLUSTERS"
echo ""

# Ask for confirmation (skip in automation)
if [ "${AUTO_CONFIRM:-false}" != "true" ]; then
    read -p "ÃŠtes-vous sÃ»r de vouloir continuer? (y/N): " -n 1 -r
    echo ""
    if [[ ! $REPLY =~ ^[Yy]$ ]]; then
        echo "âŒ OpÃ©ration annulÃ©e"
        exit 1
    fi
    echo ""
fi

# Delete HelmChartProxy first to avoid orphaned releases
echo "ğŸ—‘ï¸  Suppression des HelmChartProxy..."
HELM_CHART_PROXIES=$(kubectl get helmchartproxy --no-headers -o custom-columns=NAME:.metadata.name 2>/dev/null || echo "")
if [ -n "$HELM_CHART_PROXIES" ]; then
    for hcp in $HELM_CHART_PROXIES; do
        echo "   Suppression HelmChartProxy: $hcp"
        kubectl delete helmchartproxy "$hcp" --ignore-not-found=true
    done
    echo "   âœ… HelmChartProxy supprimÃ©s"
else
    echo "   â„¹ï¸  Aucun HelmChartProxy trouvÃ©"
fi

echo ""

# Delete all workload clusters
echo "ğŸ—‘ï¸  Suppression des workload clusters..."
for cluster in $CLUSTERS; do
    echo "   Suppression cluster: $cluster"
    kubectl delete cluster "$cluster" --ignore-not-found=true
done

echo "   âœ… Commandes de suppression envoyÃ©es"
echo ""

# Monitor deletion progress
echo "ğŸ‘€ Monitoring de la suppression..."
echo "   Appuyez sur Ctrl+C pour arrÃªter le monitoring (suppression continue en arriÃ¨re-plan)"
echo ""

start_time=$(date +%s)
while true; do
    remaining_clusters=$(kubectl get clusters --no-headers 2>/dev/null | grep -v "capi-management" | wc -l)
    remaining_machines=$(kubectl get machines --no-headers 2>/dev/null | wc -l)

    elapsed_time=$(( $(date +%s) - start_time ))

    printf "\râ±ï¸  %02d:%02d - Clusters restants: %d | Machines restantes: %d" \
        $((elapsed_time / 60)) $((elapsed_time % 60)) \
        "$remaining_clusters" "$remaining_machines"

    if [ "$remaining_clusters" -eq 0 ] && [ "$remaining_machines" -eq 0 ]; then
        echo ""
        echo ""
        echo "ğŸ‰ Suppression terminÃ©e avec succÃ¨s!"
        break
    fi

    # Timeout after 10 minutes
    if [ $elapsed_time -gt 600 ]; then
        echo ""
        echo ""
        echo "âš ï¸  Timeout aprÃ¨s 10 minutes"
        echo "   La suppression peut continuer en arriÃ¨re-plan"
        break
    fi

    sleep 3
done

echo ""
echo "ğŸ” VÃ©rification finale..."

# Check remaining resources
REMAINING_CLUSTERS=$(kubectl get clusters --no-headers 2>/dev/null | grep -v "capi-management" | wc -l)
REMAINING_MACHINES=$(kubectl get machines --no-headers 2>/dev/null | wc -l)
REMAINING_HRP=$(kubectl get helmreleaseproxy --no-headers 2>/dev/null | wc -l)

echo ""
echo "ğŸ“Š Ã‰tat final:"
echo "   Clusters workload: $REMAINING_CLUSTERS"
echo "   Machines: $REMAINING_MACHINES"
echo "   HelmReleaseProxy: $REMAINING_HRP"

# Check Docker containers
DEV_CONTAINERS=$(docker ps --filter "label=io.x-k8s.kind.cluster=dev-cluster" --format "{{.ID}}" 2>/dev/null | wc -l)
K0S_CONTAINERS=$(docker ps --filter "label=io.x-k8s.kind.cluster=k0s-demo-cluster" --format "{{.ID}}" 2>/dev/null | wc -l)
MGMT_CONTAINERS=$(docker ps --filter "label=io.x-k8s.kind.cluster=capi-management" --format "{{.ID}}" 2>/dev/null | wc -l)

echo "   Docker containers:"
echo "     Management cluster: $MGMT_CONTAINERS"
echo "     dev-cluster: $DEV_CONTAINERS"
echo "     k0s-demo-cluster: $K0S_CONTAINERS"

echo ""

# Verify management cluster is still operational
echo "ğŸ” VÃ©rification du management cluster..."
if kubectl get nodes &>/dev/null; then
    mgmt_nodes=$(kubectl get nodes --no-headers | wc -l)
    mgmt_ready=$(kubectl get nodes --no-headers | grep -c " Ready " || echo "0")
    echo "   âœ… Management cluster opÃ©rationnel ($mgmt_ready/$mgmt_nodes nodes Ready)"
else
    echo "   âŒ Management cluster inaccessible"
fi

echo ""

if [ "$REMAINING_CLUSTERS" -eq 0 ] && [ "$REMAINING_MACHINES" -eq 0 ]; then
    echo "ğŸ‰ Cleanup terminÃ© avec succÃ¨s!"
    echo ""
    echo "Ressources nettoyÃ©es:"
    echo "   âœ… Tous les workload clusters supprimÃ©s"
    echo "   âœ… Toutes les machines supprimÃ©es"
    echo "   âœ… HelmReleaseProxy nettoyÃ©s"
    echo "   âœ… Management cluster prÃ©servÃ©"
    echo ""
    echo "ğŸ” Pour vÃ©rifier l'Ã©tat complet:"
    echo "   kubectl get clusters,machines,helmreleaseproxy"
    echo "   docker ps"
    echo ""
    echo "ğŸ“ Workshop Express ClusterAPI terminÃ©! ğŸ‰"
else
    echo "âš ï¸  Cleanup partiel"
    echo ""
    echo "Ressources restantes:"
    if [ "$REMAINING_CLUSTERS" -gt 0 ]; then
        echo "   Clusters: $REMAINING_CLUSTERS"
        kubectl get clusters --no-headers | grep -v "capi-management" || true
    fi
    if [ "$REMAINING_MACHINES" -gt 0 ]; then
        echo "   Machines: $REMAINING_MACHINES"
        kubectl get machines --no-headers || true
    fi
    echo ""
    echo "ğŸ”§ Pour forcer la suppression:"
    echo "   kubectl delete clusters --all"
    echo "   kubectl delete machines --all"
    echo "   kubectl patch clusters <name> -p '{\"metadata\":{\"finalizers\":[]}}' --type=merge"
fi