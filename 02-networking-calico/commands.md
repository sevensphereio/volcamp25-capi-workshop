# Module 02: Networking avec Calico - Commandes

**Dur√©e:** 15 minutes
**Objectif:** Installer Calico CNI automatiquement avec ClusterResourceSets et passer les nodes √† Ready

---

## üìñ Partie 1: Diagnostic du Probl√®me (3 minutes)

### V√©rifier l'√©tat des nodes

```bash
cd /home/ubuntu/R_D/CLAUDE_PROJECTS/capi-workshop/workshop-express/02-networking-calico
kubectl --kubeconfig ../01-premier-cluster/dev-cluster.kubeconfig get nodes
```

**R√©sultat actuel:**
```
NAME                              STATUS     ROLES           AGE   VERSION
dev-cluster-control-plane-xxxx    NotReady   control-plane   5m    v1.28.3
dev-cluster-md-0-yyyyy-zzzzz      NotReady   <none>          4m    v1.28.3
dev-cluster-md-0-yyyyy-aaaaa      NotReady   <none>          4m    v1.28.3
```

**‚ùå STATUS: NotReady**

### Diagnostiquer la cause

```bash
kubectl --kubeconfig ../01-premier-cluster/dev-cluster.kubeconfig describe node dev-cluster-control-plane-* | grep -A 5 "Conditions:"
```

**R√©sultat cl√©:**
```
Conditions:
  Type             Status
  Ready            False
  ...
  Message: network plugin is not ready: cni config uninitialized
```

**üîç Probl√®me identifi√©:** Pas de CNI install√©!

### V√©rifier les pods kube-system

```bash
kubectl --kubeconfig ../01-premier-cluster/dev-cluster.kubeconfig get pods -n kube-system
```

**R√©sultat:**
```
NAME                                            READY   STATUS
coredns-xxx                                     0/1     Pending
coredns-yyy                                     0/1     Pending
etcd-dev-cluster-control-plane-xxxx             1/1     Running
kube-apiserver-dev-cluster-control-plane-xxxx   1/1     Running
...
```

**CoreDNS est Pending** car il attend le r√©seau pod.

---

## üìö Partie 2: Comprendre ClusterResourceSet (3 minutes)

### Qu'est-ce qu'un ClusterResourceSet?

**ClusterResourceSet (CRS)** est un m√©canisme ClusterAPI pour d√©ployer automatiquement des ressources (addons) sur les workload clusters.

### Architecture CRS

```
Management Cluster
‚îú‚îÄ‚îÄ ClusterResourceSet (d√©finit QUOI et QUAND)
‚îÇ   ‚îú‚îÄ‚îÄ clusterSelector: cni: calico  ‚Üê S√©lection par label
‚îÇ   ‚îî‚îÄ‚îÄ resources: ConfigMap calico-addon
‚îÇ
‚îú‚îÄ‚îÄ ConfigMap (contient les manifestes)
‚îÇ   ‚îî‚îÄ‚îÄ data:
‚îÇ       ‚îî‚îÄ‚îÄ calico.yaml: |
‚îÇ           <manifestes Calico complets>
‚îÇ
‚îî‚îÄ‚îÄ Clusters avec label cni: calico
    ‚Üì
    Calico appliqu√© automatiquement!
```

### Avantages CRS

‚úÖ **Automatique:** D√®s qu'un cluster a le bon label, les ressources sont appliqu√©es
‚úÖ **D√©claratif:** Tout en YAML, versionn√© dans Git
‚úÖ **R√©utilisable:** Un CRS pour tous les clusters avec le m√™me label
‚úÖ **Standard:** Pattern ClusterAPI officiel

### Explorer le manifeste

```bash
cat calico-crs.yaml | head -20
```

**R√©sultat:**
```yaml
apiVersion: addons.cluster.x-k8s.io/v1beta1
kind: ClusterResourceSet
metadata:
  name: calico-cni
spec:
  clusterSelector:
    matchLabels:
      cni: calico          ‚Üê Cherche les clusters avec ce label
  resources:
  - name: calico-addon     ‚Üê R√©f√©rence au ConfigMap
    kind: ConfigMap
  strategy: ApplyOnce      ‚Üê Appliqu√© une seule fois
---
apiVersion: v1
kind: ConfigMap
metadata:
  name: calico-addon
data:
  calico.yaml: |           ‚Üê Manifeste Calico complet (7000+ lignes)
    ...
```

---

## üöÄ Partie 3: Cr√©er le ClusterResourceSet (3 minutes)

### Appliquer le CRS

```bash
kubectl apply -f calico-crs.yaml
```

**R√©sultat attendu:**
```
clusterresourceset.addons.cluster.x-k8s.io/calico-cni created
configmap/calico-addon created
```

**2 objets cr√©√©s:**
1. **ClusterResourceSet:** D√©finit la r√®gle d'application
2. **ConfigMap:** Contient le manifeste Calico v3.26.3

### V√©rifier le CRS cr√©√©

```bash
kubectl get clusterresourceset
```

**R√©sultat:**
```
NAME         AGE
calico-cni   10s
```

### D√©tails du CRS

```bash
kubectl describe clusterresourceset calico-cni
```

**Points cl√©s:**
- Cluster Selector: `cni=calico`
- Resources: ConfigMap/calico-addon
- Strategy: ApplyOnce

---

## üè∑Ô∏è Partie 4: Activer le CRS sur le Cluster (2 minutes)

### Labeller le cluster dev-cluster

Pour que le CRS s'applique, le cluster doit avoir le label `cni: calico`:

```bash
kubectl label cluster dev-cluster cni=calico
```

**R√©sultat:**
```
cluster.cluster.x-k8s.io/dev-cluster labeled
```

**üéØ D√©clencheur:** D√®s que le label est appliqu√©, ClusterAPI d√©tecte le match et applique le CRS!

### V√©rifier le label

```bash
kubectl get cluster dev-cluster --show-labels
```

**R√©sultat:**
```
NAME          PHASE        AGE   LABELS
dev-cluster   Provisioned  10m   cni=calico,environment=demo
```

### V√©rifier l'application du CRS

```bash
kubectl get clusterresourceset calico-cni -o yaml | grep -A 10 "status:"
```

**R√©sultat attendu:**
```yaml
status:
  conditions:
  - lastTransitionTime: "2025-XX-XXT..."
    status: "True"
    type: ResourcesApplied
```

---

## üëÄ Partie 5: Observer l'Installation Calico (3 minutes)

### Observer les pods Calico appara√Ætre

```bash
watch -n 2 'kubectl --kubeconfig ../01-premier-cluster/dev-cluster.kubeconfig get pods -n kube-system'
```

**Progression attendue:**

**Minute 1:**
```
NAME                                    READY   STATUS              RESTARTS
calico-kube-controllers-xxx             0/1     ContainerCreating   0
calico-node-aaaa                        0/1     Init:0/3            0
calico-node-bbbb                        0/1     Init:0/3            0
calico-node-cccc                        0/1     Init:0/3            0
coredns-xxx                             0/1     Pending             0
coredns-yyy                             0/1     Pending             0
```

**Minute 2:**
```
NAME                                    READY   STATUS    RESTARTS
calico-kube-controllers-xxx             1/1     Running   0
calico-node-aaaa                        1/1     Running   0
calico-node-bbbb                        1/1     Running   0
calico-node-cccc                        1/1     Running   0
coredns-xxx                             1/1     Running   0
coredns-yyy                             1/1     Running   0
```

**‚úÖ Tous les pods Running!**

**Appuyez sur Ctrl+C pour arr√™ter.**

### Pods Calico D√©ploy√©s

| Pod | R√¥le | D√©ploiement |
|-----|------|-------------|
| **calico-node** | CNI agent sur chaque node | DaemonSet (1 pod/node) |
| **calico-kube-controllers** | Controller pour les policies | Deployment (1 replica) |

### Observer les nodes passer √† Ready

```bash
watch -n 2 'kubectl --kubeconfig ../01-premier-cluster/dev-cluster.kubeconfig get nodes'
```

**Progression:**

**Avant:**
```
NAME                              STATUS     ROLES           AGE
dev-cluster-control-plane-xxxx    NotReady   control-plane   10m
dev-cluster-md-0-yyyyy-zzzzz      NotReady   <none>          9m
dev-cluster-md-0-yyyyy-aaaaa      NotReady   <none>          9m
```

**Apr√®s (~1 minute):**
```
NAME                              STATUS   ROLES           AGE
dev-cluster-control-plane-xxxx    Ready    control-plane   11m
dev-cluster-md-0-yyyyy-zzzzz      Ready    <none>          10m
dev-cluster-md-0-yyyyy-aaaaa      Ready    <none>          10m
```

**‚úÖ 3/3 nodes Ready!**

---

## ‚úÖ Partie 6: Validation Finale (1 minute)

### Tester la communication r√©seau

D√©ployer un pod de test:

```bash
kubectl --kubeconfig ../01-premier-cluster/dev-cluster.kubeconfig run test-pod --image=nginx --restart=Never
```

Attendre que le pod soit Running:

```bash
kubectl --kubeconfig ../01-premier-cluster/dev-cluster.kubeconfig get pod test-pod
```

**R√©sultat:**
```
NAME       READY   STATUS    RESTARTS   AGE
test-pod   1/1     Running   0          10s
```

V√©rifier l'IP du pod (assign√©e par Calico):

```bash
kubectl --kubeconfig ../01-premier-cluster/dev-cluster.kubeconfig get pod test-pod -o wide
```

**R√©sultat:**
```
NAME       READY   STATUS    RESTARTS   AGE   IP              NODE
test-pod   1/1     Running   0          20s   192.168.X.Y     dev-cluster-md-0-...
```

**‚úÖ Pod a une IP du range 192.168.0.0/16 (configur√© dans dev-cluster.yaml)!**

### Cleanup du pod de test

```bash
kubectl --kubeconfig ../01-premier-cluster/dev-cluster.kubeconfig delete pod test-pod
```

### Ex√©cuter le script de validation

```bash
./validation.sh
```

**R√©sultat attendu:**
```
üîç Module 02: Validation Networking Calico
===========================================

‚úÖ ClusterResourceSet calico-cni existe
‚úÖ ConfigMap calico-addon existe
‚úÖ Cluster dev-cluster a le label cni=calico
‚úÖ CRS appliqu√© sur le cluster
‚úÖ Calico pods Running (4/4)
   - calico-kube-controllers: 1/1
   - calico-node DaemonSet: 3/3
‚úÖ 3/3 nodes Ready
‚úÖ CoreDNS pods Running (2/2)
‚úÖ Communication r√©seau fonctionnelle

===========================================
üéâ Module 02 termin√© avec succ√®s!
üöÄ Pr√™t pour Module 03: k0smotron Control Planes
===========================================
```

---

## üìö R√©sum√© des Concepts

| Concept | Description | Exemple |
|---------|-------------|---------|
| **CNI** | Container Network Interface - plugin r√©seau pod | Calico, Flannel, Cilium |
| **ClusterResourceSet** | D√©ploiement automatique d'addons | CRS pour Calico, CSI, etc. |
| **clusterSelector** | S√©lection de clusters par labels | `cni: calico` |
| **ConfigMap** | Stockage des manifestes √† d√©ployer | calico-addon |
| **DaemonSet** | Pod sur chaque node | calico-node |

---

## üîç Troubleshooting

### Calico pods ne d√©marrent pas
```bash
# V√©rifier les events
kubectl --kubeconfig ../01-premier-cluster/dev-cluster.kubeconfig get events -n kube-system --sort-by='.lastTimestamp'

# Logs d'un pod Calico
kubectl --kubeconfig ../01-premier-cluster/dev-cluster.kubeconfig logs -n kube-system calico-node-xxx
```

### CRS ne s'applique pas
```bash
# V√©rifier le label du cluster
kubectl get cluster dev-cluster --show-labels

# Si label manquant
kubectl label cluster dev-cluster cni=calico

# Logs du CRS controller
kubectl logs -n capi-system deployment/capi-controller-manager | grep clusterresourceset
```

### Nodes restent NotReady
```bash
# Attendre 1-2 minutes apr√®s installation Calico

# V√©rifier que tous les pods Calico sont Running
kubectl --kubeconfig ../01-premier-cluster/dev-cluster.kubeconfig get pods -n kube-system -l k8s-app=calico-node

# Si probl√®me persiste, restart kubelet (automatique dans Docker provider)
```

---

## üéì Ce Que Vous Avez Appris

‚úÖ Diagnostiquer un probl√®me de CNI manquant
‚úÖ Comprendre ClusterResourceSets pour automation
‚úÖ D√©ployer Calico automatiquement sur un cluster
‚úÖ Utiliser les labels pour d√©clencher des actions
‚úÖ Valider que le r√©seau pod fonctionne

---

## ‚è≠Ô∏è Prochaine √âtape

**Module 03 (15 min):** k0smotron Control Planes Virtuels
- Comprendre les √©conomies de ressources (55%)
- Cr√©er un cluster k0smotron √©quivalent
- Comparer les m√©triques avec Docker provider

```bash
cd ../03-k0smotron
cat commands.md
```

---

**Module 02 compl√©t√©! üéâ**
**Temps √©coul√©:** 40/90 minutes (10+15+15)
**Prochaine √©tape:** Module 03 - k0smotron Control Planes