# Module 01: Premier Cluster ClusterAPI

**Dur√©e:** 15 minutes. 
**Objectif:** Cr√©er votre premier cluster Kubernetes avec ClusterAPI Docker provider

---

## üìë Table des Mati√®res

- [üéØ Objectifs & Concepts](#-objectifs--concepts)
- [üìã Actions Pas-√†-Pas](#-actions-pas-√†-pas)
- [üí° Comprendre en Profondeur](#-comprendre-en-profondeur)

---

## üéØ Objectifs & Concepts

### Ce que vous allez apprendre

- ‚úÖ G√©n√©rer un manifeste de cluster avec clusterctl generate
- ‚úÖ Cr√©er un cluster Kubernetes d√©clarativement avec un fichier YAML
- ‚úÖ Observer la cr√©ation automatique du control plane et des workers
- ‚úÖ Comprendre pourquoi 7 objets sont n√©cessaires pour 1 cluster
- ‚úÖ Acc√©der au cluster cr√©√© et comprendre l'√©tat "NotReady"

### Le Principe : 1 Manifeste = 7 Objets

**Pourquoi 7 objets ?** S√©paration des responsabilit√©s. Chaque objet a un r√¥le pr√©cis :

```
Cluster                    ‚Üí Chef d'orchestre (coordonne tout)
‚îú‚îÄ‚îÄ DockerCluster          ‚Üí Infrastructure (r√©seau, load balancer)
‚îú‚îÄ‚îÄ KubeadmControlPlane    ‚Üí D√©finition du control plane
‚îÇ   ‚îî‚îÄ‚îÄ DockerMachineTemplate (CP) ‚Üí Template pour cr√©er les CP nodes
‚îî‚îÄ‚îÄ MachineDeployment      ‚Üí D√©finition des workers (scalable!)
    ‚îú‚îÄ‚îÄ DockerMachineTemplate (Workers) ‚Üí Template pour cr√©er les workers
    ‚îî‚îÄ‚îÄ KubeadmConfigTemplate ‚Üí Configuration bootstrap des workers
```

**Avantage :** Modifier un aspect (ex: version K8s) = modifier 1 seul objet, pas tout refaire.

---

## üìã Actions Pas-√†-Pas

> **üí° Raccourci :** Pour un setup automatis√© complet, utilisez `./create-cluster.sh` qui ex√©cute toutes les √©tapes ci-dessous. Pour une compr√©hension d√©taill√©e, suivez les √©tapes manuelles.

### √âtape 1 : Aller dans le r√©pertoire du module

**Objectif :** Se positionner dans le dossier de travail

**Commande :**
```bash
cd ~/01-premier-cluster
```

**Explication :**
- `cd` : Change de r√©pertoire
- Chemin absolu vers le module 01

---

### √âtape 2 : G√©n√©rer le manifeste dev-cluster.yaml avec clusterctl

**Objectif :** Utiliser clusterctl pour g√©n√©rer automatiquement un manifeste de cluster complet

**Commande :**
```bash
clusterctl generate cluster dev-cluster \
  --flavor development \
  --kubernetes-version v1.32.8 \
  --control-plane-machine-count=1 \
  --worker-machine-count=2 \
  > dev-cluster.yaml
```

**Explication de la commande :**
- `clusterctl generate cluster` : Commande pour g√©n√©rer un manifeste de cluster
- `dev-cluster` : Nom du cluster √† cr√©er
- `--flavor development` : Utilise le template "development" (optimis√© pour dev local)
- `--kubernetes-version v1.32.8` : Version de Kubernetes √† installer
- `--control-plane-machine-count=1` : 1 node control plane (suffisant pour dev)
- `--worker-machine-count=2` : 2 nodes workers
- `> dev-cluster.yaml` : Redirige la sortie vers un fichier

**Pourquoi cette approche ?**
- ‚úÖ **Toujours √† jour** : Templates maintenus par la communaut√© ClusterAPI
- ‚úÖ **Bonnes pratiques** : Configuration optimale selon le provider
- ‚úÖ **Flexible** : Facile de changer les param√®tres (version, nombre de nodes)
- ‚úÖ **Reproductible** : M√™me commande = m√™me r√©sultat

**R√©sultat attendu :** Fichier `dev-cluster.yaml` cr√©√© (~200 lignes)

**‚úÖ V√©rification :**
```bash
ls -lh dev-cluster.yaml
```

Vous devriez voir un fichier d'environ 7-8 KB

---

### √âtape 3 : Examiner le manifeste g√©n√©r√©

**Objectif :** Comprendre la structure du fichier avant de l'appliquer

**Commande :**
```bash
cat dev-cluster.yaml
```

**Explication :**
- `cat` : Affiche le contenu d'un fichier
- `dev-cluster.yaml` : Le manifeste contenant les 7 objets ClusterAPI

**R√©sultat attendu :** Un fichier YAML avec 7 sections (objets) s√©par√©es par `---`

**‚úÖ V√©rification :** Rep√©rez les 7 types d'objets g√©n√©r√©s automatiquement :
1. `kind: Cluster` - Chef d'orchestre (coordonne tout)
2. `kind: DockerCluster` - Infrastructure (r√©seau, load balancer)
3. `kind: KubeadmControlPlane` - D√©finition du control plane
4. `kind: DockerMachineTemplate` pour CP - Template pour cr√©er les CP nodes
5. `kind: MachineDeployment` - D√©finition des workers (scalable!)
6. `kind: DockerMachineTemplate` pour workers - Template pour cr√©er les workers
7. `kind: KubeadmConfigTemplate` - Configuration bootstrap des workers

**üîç Points cl√©s √† noter dans le manifeste g√©n√©r√© :**
- **Cluster** : Contient uniquement des r√©f√©rences (`controlPlaneRef`, `infrastructureRef`)
- **KubeadmControlPlane** : `replicas: 1` (1 control plane node) et `version: v1.32.8`
- **MachineDeployment** : `replicas: 2` (2 worker nodes)
- **Networking** : CIDR pour les pods et services pr√©-configur√©

**Commandes d'exploration :**
```bash
# Compter le nombre d'objets
grep -c "^kind:" dev-cluster.yaml

# Lister tous les types d'objets
grep "^kind:" dev-cluster.yaml

# Voir uniquement le Cluster principal
yq eval 'select(.kind == "Cluster")' dev-cluster.yaml 2>/dev/null || head -n 20 dev-cluster.yaml
```

---

### √âtape 4 : Cr√©er le cluster

**Objectif :** Envoyer le manifeste √† ClusterAPI pour cr√©er le cluster

**Commande :**
```bash
kubectl apply -f dev-cluster.yaml
```

**Explication de la commande :**
- `kubectl apply` : Cr√©e ou met √† jour des ressources Kubernetes
- `-f` : Sp√©cifie un fichier (file) √† utiliser
- `dev-cluster.yaml` : Le fichier manifeste

**R√©sultat attendu :**
```
cluster.cluster.x-k8s.io/dev-cluster created
dockercluster.infrastructure.cluster.x-k8s.io/dev-cluster created
kubeadmcontrolplane.controlplane.cluster.x-k8s.io/dev-cluster-control-plane created
dockermachinetemplate.infrastructure.cluster.x-k8s.io/dev-cluster-control-plane created
machinedeployment.cluster.x-k8s.io/dev-cluster-md-0 created
dockermachinetemplate.infrastructure.cluster.x-k8s.io/dev-cluster-md-0 created
kubeadmconfigtemplate.bootstrap.cluster.x-k8s.io/dev-cluster-md-0 created
```

**‚úÖ V√©rification :** 7 objets cr√©√©s confirm√©s

**üîç Ce qui se passe :**
1. Les objets sont enregistr√©s dans l'API du management cluster
2. Les controllers ClusterAPI d√©tectent les nouveaux objets
3. La cr√©ation automatique d√©marre (containers, r√©seau, Kubernetes)

---

### √âtape 5 : Observer la cr√©ation en temps r√©el

**Objectif :** Suivre la progression de Pending ‚Üí Provisioning ‚Üí Provisioned

**Commande :**
```bash
watch -n 2 'kubectl get clusters,machines'
```

**Explication de la commande :**
- `watch` : Ex√©cute une commande en boucle
- `-n 2` : Rafra√Æchit toutes les 2 secondes
- `kubectl get clusters,machines` : Liste les clusters et machines
- Guillemets simples pour prot√©ger la commande enti√®re

**R√©sultat attendu (progression sur 3 minutes) :**

**Minute 1 - D√©marrage :**
```
NAME                                    PHASE      AGE
cluster.cluster.x-k8s.io/dev-cluster    Pending    30s

NAME                                                  CLUSTER       PHASE         AGE
machine.cluster.x-k8s.io/dev-cluster-control-plane-xxxx  dev-cluster   Provisioning  30s
machine.cluster.x-k8s.io/dev-cluster-md-0-yyyyy-zzzzz    dev-cluster   Pending       30s
machine.cluster.x-k8s.io/dev-cluster-md-0-yyyyy-aaaaa    dev-cluster   Pending       30s
```

**Minute 2 - Control plane up :**
```
NAME                                    PHASE           AGE
cluster.cluster.x-k8s.io/dev-cluster    Provisioning    2m

NAME                                                  CLUSTER       PHASE         AGE
machine.cluster.x-k8s.io/dev-cluster-control-plane-xxxx  dev-cluster   Running       2m
machine.cluster.x-k8s.io/dev-cluster-md-0-yyyyy-zzzzz    dev-cluster   Provisioning  2m
machine.cluster.x-k8s.io/dev-cluster-md-0-yyyyy-aaaaa    dev-cluster   Provisioning  2m
```

**Minute 3 - Cluster complet :**
```
NAME                                    PHASE         AGE
cluster.cluster.x-k8s.io/dev-cluster    Provisioned   3m

NAME                                                  CLUSTER       PHASE     AGE
machine.cluster.x-k8s.io/dev-cluster-control-plane-xxxx  dev-cluster   Running   3m
machine.cluster.x-k8s.io/dev-cluster-md-0-yyyyy-zzzzz    dev-cluster   Running   3m
machine.cluster.x-k8s.io/dev-cluster-md-0-yyyyy-aaaaa    dev-cluster   Running   3m
```

**‚úÖ V√©rification finale :** Cluster PHASE = Provisioned, 3 Machines PHASE = Running

**üîç Phases expliqu√©es :**
- **Pending** : Objet cr√©√©, en attente de provisioning
- **Provisioning** : Infrastructure en cours de cr√©ation
- **Running** : Machine op√©rationnelle (pour Machine)
- **Provisioned** : Cluster complet et pr√™t (pour Cluster)

**Appuyez sur Ctrl+C pour arr√™ter le watch**

---

### √âtape 6 : V√©rifier les containers Docker cr√©√©s

**Objectif :** Confirmer que 3 containers = 3 nodes Kubernetes

**Commande :**
```bash
docker ps | grep dev-cluster
```

**Explication de la commande :**
- `docker ps` : Liste les containers Docker en cours d'ex√©cution
- `|` : Pipe (envoie la sortie vers la commande suivante)
- `grep dev-cluster` : Filtre uniquement les lignes contenant "dev-cluster"

**R√©sultat attendu :**
```
CONTAINER ID   IMAGE                  NAMES
xxxxxxxxxxxx   kindest/node:v1.32.8   dev-cluster-control-plane-xxxx
yyyyyyyyyyyy   kindest/node:v1.32.8   dev-cluster-md-0-yyyyy-zzzzz
zzzzzzzzzzzz   kindest/node:v1.32.8   dev-cluster-md-0-yyyyy-aaaaa
```

**‚úÖ V√©rification :** 3 containers list√©s

**üîç Ce que cela signifie :**
- Chaque container Docker simule une machine virtuelle
- `kindest/node` : Image Docker pr√©-configur√©e avec Kubernetes
- 1 container pour le control plane + 2 containers pour les workers

---

### √âtape 7 : Explorer les ressources ClusterAPI

**Objectif :** V√©rifier l'√©tat d√©taill√© des composants

**Commandes :**

**6.1 - Voir le KubeadmControlPlane**
```bash
kubectl get kubeadmcontrolplane
```

**Explication :**
- `get kubeadmcontrolplane` : Liste les control planes g√©r√©s par ClusterAPI

**R√©sultat attendu :**
```
NAME                         CLUSTER       INITIALIZED   API SERVER   REPLICAS   READY   UPDATED
dev-cluster-control-plane    dev-cluster   true          true         1          1       1
```

**‚úÖ V√©rification :** INITIALIZED = true, API SERVER = true, READY = 1/1

---

**6.2 - Voir le MachineDeployment**
```bash
kubectl get machinedeployment
```

**Explication :**
- `get machinedeployment` : Liste les d√©ploiements de workers (comme un Deployment K8s)

**R√©sultat attendu :**
```
NAME                 CLUSTER       REPLICAS   READY   UPDATED   UNAVAILABLE   PHASE     AGE
dev-cluster-md-0     dev-cluster   2          2       2         0             Running   3m
```

**‚úÖ V√©rification :** REPLICAS = 2, READY = 2, PHASE = Running

---

**6.3 - Voir les Machines d√©taill√©es**
```bash
kubectl get machines -o wide
```

**Explication :**
- `get machines` : Liste toutes les machines (CP + workers)
- `-o wide` : Format √©tendu avec plus d'informations (VERSION, NODENAME)

**R√©sultat attendu :**
```
NAME                                CLUSTER       PHASE     VERSION   NODENAME
dev-cluster-control-plane-xxxx      dev-cluster   Running   v1.32.8   dev-cluster-control-plane-xxxx
dev-cluster-md-0-yyyyy-zzzzz        dev-cluster   Running   v1.32.8   dev-cluster-md-0-yyyyy-zzzzz
dev-cluster-md-0-yyyyy-aaaaa        dev-cluster   Running   v1.32.8   dev-cluster-md-0-yyyyy-aaaaa
```

**‚úÖ V√©rification :** 3 machines en phase Running avec la version v1.32.8

---

### √âtape 8 : R√©cup√©rer le kubeconfig du workload cluster

**Objectif :** Obtenir le fichier de configuration pour acc√©der au nouveau cluster

**Commande :**
```bash
clusterctl get kubeconfig dev-cluster > dev-cluster.kubeconfig
```

**Explication de la commande :**
- `clusterctl` : Outil CLI sp√©cifique √† ClusterAPI
- `get kubeconfig` : Extrait le fichier kubeconfig du cluster sp√©cifi√©
- `dev-cluster` : Nom du cluster cible
- `>` : Redirige la sortie vers un fichier
- `dev-cluster.kubeconfig` : Nom du fichier de sortie

**R√©sultat attendu :** Pas de sortie (le fichier est cr√©√© silencieusement)

**‚úÖ V√©rification :**
```bash
ls -lh dev-cluster.kubeconfig
```

Vous devriez voir un fichier d'environ 5-6 KB

---

### √âtape 9 : Acc√©der au workload cluster

**Objectif :** Voir les nodes dans le cluster nouvellement cr√©√©

**Commande :**
```bash
kubectl --kubeconfig dev-cluster.kubeconfig get nodes
```

**Explication de la commande :**
- `kubectl` : Commande habituelle
- `--kubeconfig dev-cluster.kubeconfig` : Utilise ce fichier au lieu du kubeconfig par d√©faut
- `get nodes` : Liste les nodes Kubernetes

**R√©sultat attendu :**
```
NAME                              STATUS     ROLES           AGE   VERSION
dev-cluster-control-plane-xxxx    NotReady   control-plane   3m    v1.32.8
dev-cluster-md-0-yyyyy-zzzzz      NotReady   <none>          2m    v1.32.8
dev-cluster-md-0-yyyyy-aaaaa      NotReady   <none>          2m    v1.32.8
```

**‚úÖ V√©rification :** 3 nodes list√©s avec VERSION v1.32.8

**‚ö†Ô∏è STATUS = NotReady est NORMAL !** Le CNI (Container Network Interface) n'est pas encore install√©.

---

### √âtape 10 : Comprendre pourquoi NotReady

**Objectif :** V√©rifier l'absence du r√©seau pod

**Commande :**
```bash
kubectl --kubeconfig dev-cluster.kubeconfig get pods -A
```

**Explication de la commande :**
- `--kubeconfig dev-cluster.kubeconfig` : Utilise le workload cluster
- `get pods` : Liste les pods
- `-A` : Dans tous les namespaces (All)

**R√©sultat attendu :**
```
NAMESPACE     NAME                                                READY   STATUS
kube-system   coredns-xxx                                         0/1     Pending
kube-system   coredns-yyy                                         0/1     Pending
kube-system   etcd-dev-cluster-control-plane-xxxx                 1/1     Running
kube-system   kube-apiserver-dev-cluster-control-plane-xxxx       1/1     Running
kube-system   kube-controller-manager-dev-cluster-...             1/1     Running
kube-system   kube-proxy-...                                      1/1     Running
kube-system   kube-scheduler-dev-cluster-control-plane-xxxx       1/1     Running
```

**‚úÖ V√©rification :**
- Control plane pods (etcd, apiserver, etc.) = Running
- CoreDNS pods = Pending

**üîç Diagnostic :**
- CoreDNS ne peut pas d√©marrer sans r√©seau pod
- Les nodes ne peuvent pas communiquer entre eux sans CNI
- **Module 02 r√©soudra ce probl√®me avec Calico CNI**

---

### √âtape 11 : Valider le module

**Objectif :** Ex√©cuter le script de validation automatique

**Commande :**
```bash
./validation.sh
```

**Explication :**
- `./` : Ex√©cute un script dans le r√©pertoire courant
- `validation.sh` : Script bash qui teste tous les pr√©requis

**R√©sultat attendu :**
```
üîç Module 01: Validation Premier Cluster
=========================================

‚úÖ Cluster dev-cluster existe
‚úÖ Cluster phase = Provisioned
‚úÖ Control plane ready (1/1)
‚úÖ 3 Machines en phase Running
‚úÖ Kubeconfig r√©cup√©rable
‚úÖ 3 nodes visibles dans le workload cluster
‚ö†Ô∏è  Nodes NotReady (normal - CNI manquant)

=========================================
üéâ Module 01 termin√© avec succ√®s!
üöÄ Pr√™t pour Module 02: Networking avec Calico
=========================================
```

**‚úÖ Si tous les tests passent :** Vous √™tes pr√™t pour le Module 02 !

---

## üéì Points Cl√©s √† Retenir

‚úÖ **1 YAML = 7 objets interconnect√©s** - S√©paration des responsabilit√©s
‚úÖ **Machine ‚â† Node** - Machine (CRD ClusterAPI) cr√©e une infra qui devient un Node (objet K8s)
‚úÖ **Phases du Lifecycle** : Pending ‚Üí Provisioning ‚Üí Running/Provisioned
‚úÖ **MachineDeployment = Deployment pour nodes** - Scaling : `kubectl scale machinedeployment`
‚úÖ **NotReady est normal ici** - Le CNI (r√©seau) sera install√© au Module 02

### Tableau R√©capitulatif des Objets

| Objet | R√¥le | Analogie |
|-------|------|----------|
| **Cluster** | Chef d'orchestre (r√©f√©rences seulement) | Chef de projet qui coordonne |
| **DockerCluster** | Infrastructure (LB, r√©seau) | Terrain et fondations |
| **KubeadmControlPlane** | D√©finition du control plane | Direction g√©n√©rale (CEO, CTO) |
| **DockerMachineTemplate (CP)** | Template pour cr√©er les CP nodes | Moule √† g√¢teau CP |
| **MachineDeployment** | D√©finition des workers (scalable) | Manager des workers |
| **DockerMachineTemplate (Workers)** | Template pour cr√©er les workers | Moule √† g√¢teau workers |
| **KubeadmConfigTemplate** | Configuration bootstrap workers | Script d'onboarding |

---

## ‚è≠Ô∏è Prochaine √âtape

**Module 02-networking-calico (15 min) :** Installer Calico CNI automatiquement
- Comprendre ClusterResourceSets
- Automatiser le d√©ploiement de Calico
- Passer les nodes √† Ready


---

## üí° Comprendre en Profondeur

> **Note :** Cette section approfondit les concepts techniques. Vous pouvez la sauter et y revenir plus tard.

### Workflow Complet "Sous le Capot"

**Ce qui se passe apr√®s `kubectl apply` :**

```
T+0s   : kubectl envoie les 7 objets √† l'API server du management cluster
T+1s   : ClusterAPI controller d√©tecte le nouveau Cluster ‚Üí d√©marre reconciliation
T+2s   : DockerCluster controller cr√©e le load balancer (container haproxy)
T+5s   : KubeadmControlPlane controller cr√©e la premi√®re Machine pour le CP
T+10s  : Docker provider cr√©e un container kindest/node pour le CP
T+30s  : Kubeadm bootstrap installe Kubernetes dans le container
T+60s  : Control plane UP! API server accessible
T+65s  : MachineDeployment d√©tecte CP ready ‚Üí cr√©e 2 Machines workers
T+70s  : Docker provider cr√©e 2 containers pour les workers
T+120s : Workers joignent le control plane via kubeadm join
T+180s : üéâ Cluster Provisioned! (Mais nodes NotReady - pas de CNI encore)
```

**Pourquoi c'est rapide (3 minutes) ?**
- **Containers vs VMs** : 10x plus rapide
- **Images pr√©-built** : kindest/node pr√©-configur√© avec K8s
- **Parall√©lisation** : Workers cr√©√©s en parall√®le
- **En prod (AWS)** : Comptez 5-8 minutes (provisioning VMs + cloud API)

---

### Anatomie Compl√®te des 7 Objets

#### 1Ô∏è‚É£ Cluster - Le Chef d'Orchestre

**R√¥le :** Coordination de haut niveau

```yaml
apiVersion: cluster.x-k8s.io/v1beta1
kind: Cluster
metadata:
  name: dev-cluster
spec:
  clusterNetwork:
    pods:
      cidrBlocks: ["192.168.0.0/16"]   # R√©seau pour 65k pods
  controlPlaneRef:
    kind: KubeadmControlPlane          # R√©f√©rence au CP
    name: dev-cluster-control-plane
  infrastructureRef:
    kind: DockerCluster                # R√©f√©rence √† l'infra
    name: dev-cluster
```

**Points cl√©s :**
- Ne contient QUE des r√©f√©rences (pas d'impl√©mentation)
- D√©finit le r√©seau pod (important pour CNI)
- Controller ClusterAPI surveille cet objet pour orchestrer

**Pourquoi des r√©f√©rences ?**
- **Modularit√©** : Changer de provider = changer 1 r√©f√©rence
- **R√©utilisabilit√©** : M√™me DockerCluster pour plusieurs Clusters
- **S√©paration** : Logique m√©tier vs impl√©mentation

---

#### 2Ô∏è‚É£ DockerCluster - L'Infrastructure Concr√®te

**R√¥le :** Cr√©er l'infrastructure r√©seau et load balancer

```yaml
kind: DockerCluster
metadata:
  name: dev-cluster
spec: {}  # Vide pour Docker, contiendrait VPC/subnets pour AWS
```

**Ce qu'il fait r√©ellement :**
- Cr√©e un container **haproxy** pour load balancer l'API server
- Configure le r√©seau Docker pour la communication inter-containers
- En prod (AWS) : d√©finirait VPC, subnets, security groups, internet gateway

**Portabilit√© :**
```yaml
# Production AWS
kind: AWSCluster
spec:
  region: us-west-2
  vpc:
    cidrBlock: "10.0.0.0/16"
```

---

#### 3Ô∏è‚É£ KubeadmControlPlane - Le Cerveau du Cluster

**R√¥le :** G√©rer le control plane (API server, etcd, scheduler, controller-manager)

```yaml
kind: KubeadmControlPlane
metadata:
  name: dev-cluster-control-plane
spec:
  replicas: 1           # Nombre de nodes CP (3 en prod pour HA)
  version: v1.32.8      # Version Kubernetes √† installer
  machineTemplate:
    infrastructureRef:
      kind: DockerMachineTemplate
      name: dev-cluster-control-plane
  kubeadmConfigSpec:    # Configuration kubeadm pour initialiser K8s
    initConfiguration:
      nodeRegistration:
        criSocket: unix:///var/run/containerd/containerd.sock
```

**Responsabilit√©s :**
- Cr√©e les nodes control plane
- G√®re les certificats CA du cluster
- Automatise `kubeadm init` et `kubeadm join` pour les CP
- HA automatique si replicas > 1 (quorum etcd)

**Scaling du Control Plane :**
```
replicas: 1 ‚Üí Dev/Test (panne = cluster down)
replicas: 3 ‚Üí Production (tol√®re 1 panne, quorum 2/3)
replicas: 5 ‚Üí Mission-critical (tol√®re 2 pannes)
```

**Important :** Toujours un nombre **impair** pour le quorum etcd

---

#### 4Ô∏è‚É£ DockerMachineTemplate (CP) - Moule √† Serveurs CP

**R√¥le :** Template r√©utilisable pour cr√©er les machines control plane

```yaml
kind: DockerMachineTemplate
metadata:
  name: dev-cluster-control-plane
spec:
  template:
    spec:
      extraMounts:
        - containerPath: /var/run/docker.sock
          hostPath: /var/run/docker.sock
```

**Points cl√©s :**
- N'est PAS instanci√© directement (c'est un template)
- KubeadmControlPlane l'utilise pour cr√©er des Machines
- Contient : ressources CPU/RAM, disques, configuration r√©seau
- En prod : type d'instance (t3.medium), AMI, security groups

---

#### 5Ô∏è‚É£ MachineDeployment - Manager des Workers

**R√¥le :** G√©rer les worker nodes (comme un Deployment K8s mais pour serveurs)

```yaml
kind: MachineDeployment
metadata:
  name: dev-cluster-md-0
spec:
  clusterName: dev-cluster
  replicas: 2                  # 2 worker nodes (scalable √† tout moment)
  selector:
    matchLabels:
      cluster.x-k8s.io/cluster-name: dev-cluster
  template:
    spec:
      version: v1.32.8
      bootstrap:
        configRef:
          kind: KubeadmConfigTemplate
      infrastructureRef:
        kind: DockerMachineTemplate
```

**Fonctionnalit√©s identiques √† un Deployment K8s :**
- **Scaling** : `kubectl scale machinedeployment dev-cluster-md-0 --replicas=5`
- **Rolling updates** : Changement de version ‚Üí update progressif
- **Self-healing** : Machine down = recr√©ation automatique

**Pourquoi s√©par√© du Control Plane ?**
```
Control Plane = Critique ‚Üí KubeadmControlPlane (gestion sp√©ciale, quorum)
Workers = Scalables ‚Üí MachineDeployment (scaling facile, jetables)
```

---

#### 6Ô∏è‚É£ DockerMachineTemplate (Workers) - Moule √† Workers

**R√¥le :** Template pour cr√©er les worker machines (m√™me principe que template CP)

```yaml
kind: DockerMachineTemplate
metadata:
  name: dev-cluster-md-0
spec:
  template:
    spec:
      extraMounts:
        - containerPath: /var/run/docker.sock
          hostPath: /var/run/docker.sock
```

---

#### 7Ô∏è‚É£ KubeadmConfigTemplate - Script d'Installation Workers

**R√¥le :** Automatiser le bootstrap (jointure) des workers au control plane

```yaml
kind: KubeadmConfigTemplate
metadata:
  name: dev-cluster-md-0
spec:
  template:
    spec:
      joinConfiguration:
        nodeRegistration:
          criSocket: unix:///var/run/containerd/containerd.sock
          kubeletExtraArgs:
            eviction-hard: nodefs.available<0%,nodefs.inodesFree<0%
```

**Ce qu'il fait :**
- Contient les commandes `kubeadm join` pr√©-configur√©es
- Injecte automatiquement certificats et tokens
- Configure kubelet avec les bonnes options

**Workflow automatique :**
1. MachineDeployment cr√©e une nouvelle Machine
2. Docker provider cr√©e un container
3. KubeadmConfigTemplate g√©n√®re un cloud-init script
4. Script ex√©cut√© dans le container ‚Üí `kubeadm join`
5. Worker rejoint automatiquement le cluster

---

### Diff√©rence Machine vs Node

**Confusion fr√©quente :** Les termes sont souvent m√©lang√©s, mais ils sont distincts !

| Aspect | Machine (CRD ClusterAPI) | Node (Objet Kubernetes) |
|--------|--------------------------|-------------------------|
| **D√©finition** | D√©finition d√©clarative d'un serveur | Serveur r√©el enregistr√© dans K8s |
| **O√π vit-il ?** | Management cluster | Workload cluster |
| **Lifecycle** | Pending ‚Üí Provisioning ‚Üí Running | NotReady ‚Üí Ready |
| **Gestion** | ClusterAPI controllers | Kubelet |
| **Commande** | `kubectl get machines` | `kubectl get nodes` |

**Workflow complet :**
```
1. MachineDeployment cr√©e ‚Üí 1 Machine (CRD)
2. Machine d√©clenche ‚Üí Cr√©ation infrastructure (VM/container)
3. Infrastructure d√©marre ‚Üí Kubelet s'enregistre
4. Kubelet cr√©e ‚Üí 1 Node (objet K8s)
5. Machine.status.nodeRef pointe vers le Node
```

---

### Pourquoi NotReady est Normal

**Les nodes sont cr√©√©s mais non fonctionnels car :**

1. **CNI manquant** : Pas de plugin r√©seau install√©
2. **Pas de communication pod-to-pod** : Les pods ne peuvent pas se parler
3. **CoreDNS bloqu√©** : Attend le r√©seau pour d√©marrer

**V√©rification :**
```bash
kubectl --kubeconfig dev-cluster.kubeconfig describe node <node-name> | grep -A 5 "Conditions:"
```

Vous verrez :
```
Conditions:
  Type             Status  Reason
  ----             ------  ------
  Ready            False   KubeletNotReady
  NetworkReady     False   NetworkPluginNotReady
```

**Solution :** Module 02 installera Calico CNI via ClusterResourceSet automatiquement !

---

### Scaling en Pratique

**Scaler les workers (MachineDeployment) :**

```bash
# M√©thode 1 : kubectl scale
kubectl scale machinedeployment dev-cluster-md-0 --replicas=5

# M√©thode 2 : kubectl patch
kubectl patch machinedeployment dev-cluster-md-0 -p '{"spec":{"replicas":5}}'

# M√©thode 3 : Modifier le YAML et r√©-appliquer
# √âditer dev-cluster.yaml : replicas: 5
kubectl apply -f dev-cluster.yaml
```

**Workflow automatique :**
1. MachineDeployment d√©tecte `desired: 5, current: 2`
2. Cr√©e 3 nouvelles Machines
3. Utilise DockerMachineTemplate pour les cr√©er
4. Utilise KubeadmConfigTemplate pour les configurer
5. Machines joignent automatiquement le cluster
6. √âtat final : 5 workers Running

**Observer le scaling :**
```bash
watch -n 2 'kubectl get machines'
```

---

### Upgrade de Version Kubernetes

**Changer la version K8s :**

```bash
# Upgrade le control plane
kubectl patch kubeadmcontrolplane dev-cluster-control-plane \
  -p '{"spec":{"version":"v1.33.0"}}' --type=merge

# Upgrade les workers
kubectl patch machinedeployment dev-cluster-md-0 \
  -p '{"spec":{"template":{"spec":{"version":"v1.33.0"}}}}' --type=merge
```

**Workflow automatique :**
1. **Control plane** : Rolling update (1 node √† la fois si replicas > 1)
2. **Workers** : Rolling update (comme un Deployment K8s)
3. Chaque node est drain√© ‚Üí upgrad√© ‚Üí rejoint le cluster
4. **Zero-downtime** si con√ßu pour HA

---

### Connexion Production

**En production AWS/Azure, seuls 2-3 objets changent :**

```yaml
# Au lieu de DockerCluster :
kind: AWSCluster
spec:
  region: us-west-2
  vpc:
    cidrBlock: "10.0.0.0/16"
    availabilityZones: ["us-west-2a", "us-west-2b", "us-west-2c"]

# Au lieu de DockerMachineTemplate :
kind: AWSMachineTemplate
spec:
  template:
    spec:
      instanceType: t3.medium
      ami:
        id: ami-0abcdef1234567890
      iamInstanceProfile: nodes.cluster-api-provider-aws.sigs.k8s.io
      sshKeyName: my-ssh-key

# Le reste (Cluster, KubeadmControlPlane, MachineDeployment) ‚Üí IDENTIQUE !
```

**Portabilit√© r√©elle :**
- 80% du manifeste reste identique
- Changer de provider = remplacer 2 objets sur 7
- M√™me commande : `kubectl apply -f cluster.yaml`

---

### Troubleshooting

#### Cluster reste en Pending

**Diagnostic :**
```bash
# V√©rifier les events du cluster
kubectl describe cluster dev-cluster

# Logs du controller ClusterAPI
kubectl logs -n capi-system deployment/capi-controller-manager -f

# Logs du Docker provider
kubectl logs -n capd-system deployment/capd-controller-manager -f
```

**Causes fr√©quentes :**
- Infrastructure provider down
- R√©f√©rence incorrecte dans le manifeste
- Ressources insuffisantes (Docker)

---

#### Machine ne d√©marre pas

**Diagnostic :**
```bash
# D√©tails de la machine
kubectl describe machine <machine-name>

# V√©rifier les containers Docker
docker ps -a | grep dev-cluster

# Logs du container si cr√©√©
docker logs <container-name>
```

**Causes fr√©quentes :**
- Image kindest/node non disponible
- Erreur r√©seau Docker
- Port d√©j√† utilis√© (load balancer)

---

#### Kubeconfig inaccessible

**Diagnostic :**
```bash
# Le cluster doit √™tre Provisioned
kubectl get cluster dev-cluster -o jsonpath='{.status.phase}'
# Doit afficher : Provisioned

# V√©rifier que le control plane est ready
kubectl get kubeadmcontrolplane
# Doit montrer : INITIALIZED=true, API SERVER=true
```

**Solution :**
```bash
# Attendre que le cluster soit Provisioned
# Puis retry :
clusterctl get kubeconfig dev-cluster > dev-cluster.kubeconfig
```

---

### Pause P√©dagogique : Questions de Compr√©hension

#### Question 1
**Si vous voulez scaler de 2 √† 5 workers, quel objet modifiez-vous ?**

<details>
<summary>Voir la r√©ponse</summary>

**R√©ponse :** `MachineDeployment` - modifier `spec.replicas: 5`

```bash
kubectl scale machinedeployment dev-cluster-md-0 --replicas=5
```
</details>

---

#### Question 2
**Quelle diff√©rence entre KubeadmControlPlane et MachineDeployment ?**

<details>
<summary>Voir la r√©ponse</summary>

| Aspect | KubeadmControlPlane | MachineDeployment |
|--------|---------------------|-------------------|
| **Cible** | Nodes control plane | Nodes workers |
| **Criticit√©** | Critique (cerveau cluster) | Scalable (ex√©cution apps) |
| **HA** | Gestion sp√©ciale (quorum etcd) | Simple r√©plication |
| **Scaling** | Chiffres impairs (1,3,5) | N'importe quel nombre |
| **Upgrade** | Rolling upgrade prudent | Rolling upgrade standard |

**Pourquoi s√©par√© ?** Le control plane g√®re l'√©tat du cluster entier. Les workers sont "jetables" et facilement rempla√ßables.
</details>

---

#### Question 3
**Pourquoi 7 objets au lieu d'un seul gros fichier ?**

<details>
<summary>Voir la r√©ponse</summary>

**Avantages de la s√©paration :**
1. **Modularit√©** : Changer la version K8s = modifier 1 objet (KubeadmControlPlane)
2. **R√©utilisabilit√©** : M√™me template pour plusieurs d√©ploiements
3. **Portabilit√©** : Changer de provider = remplacer 2 objets sur 7
4. **Scaling** : Modifier replicas sans toucher au reste
5. **Responsabilit√© unique** : Chaque objet a UN r√¥le pr√©cis

**Exemple :** Pour passer de Docker √† AWS :
- Remplacer DockerCluster ‚Üí AWSCluster
- Remplacer DockerMachineTemplate ‚Üí AWSMachineTemplate
- Garder : Cluster, KubeadmControlPlane, MachineDeployment, KubeadmConfigTemplate
</details>

---

## üéì Ce Que Vous Avez Appris

- ‚úÖ Cr√©er un cluster Kubernetes d√©clarativement (1 YAML = 7 objets)
- ‚úÖ Observer la progression en temps r√©el (Pending ‚Üí Provisioned)
- ‚úÖ Comprendre l'architecture √† 7 objets interconnect√©s
- ‚úÖ Diff√©rencier Machines (CRD ClusterAPI) et Nodes (objet K8s)
- ‚úÖ Acc√©der au workload cluster avec kubeconfig
- ‚úÖ Diagnostiquer pourquoi les nodes sont NotReady (CNI manquant)
- ‚úÖ Scaler les workers avec `kubectl scale`

---

**Module 01 compl√©t√© ! üéâ**
**Temps √©coul√© :** 25/90 minutes (10+15)
**Prochaine √©tape :** Module 02 - Networking avec Calico