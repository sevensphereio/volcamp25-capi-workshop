# Module 00-setup: Installation du Cluster de Management

**Dur√©e:** 15 minutes
**Objectif:** Cr√©er le cluster de management kind et installer tous les composants ClusterAPI n√©cessaires

---

## üìë Table des Mati√®res

- [üéØ Objectifs & Concepts](#-objectifs--concepts)
- [üìã Actions Pas-√†-Pas](#-actions-pas-√†-pas)
- [üí° Comprendre en Profondeur](#-comprendre-en-profondeur)

---

## üéØ Objectifs & Concepts

### Ce que vous allez apprendre

‚úÖ Cr√©er un cluster de management kind configur√© pour ClusterAPI
‚úÖ Initialiser ClusterAPI avec le provider Docker (CAPD)
‚úÖ Comprendre l'architecture Management vs Workload clusters

### Le Principe : Management Cluster = Usine √† Clusters

**Analogie :** Le cluster de management est comme une **usine automobile**. L'usine elle-m√™me ne transporte pas de passagers, mais elle fabrique des voitures (workload clusters) qui le font.

```
Management Cluster (kind)
‚îú‚îÄ‚îÄ ClusterAPI Controllers     ‚Üí Chefs d'atelier (orchestrent la fabrication)
‚îî‚îÄ‚îÄ Docker Provider            ‚Üí Cha√Æne d'assemblage Docker

Produit ‚Üí Workload Clusters
‚îú‚îÄ‚îÄ dev-cluster (Docker)       ‚Üí Voiture de d√©veloppement
‚îú‚îÄ‚îÄ k0s-demo-cluster           ‚Üí Voiture √©lectrique (plus √©conome, provider install√© plus tard)
‚îî‚îÄ‚îÄ multi-clusters             ‚Üí Flotte de v√©hicules
```

**Pourquoi s√©parer Management et Workload ?**
- **S√©curit√©** : Le control plane de la fabrique est isol√© des applications
- **Stabilit√©** : Un workload cluster crash√© n'affecte pas les autres
- **Scalabilit√©** : 1 management cluster peut g√©rer 100+ workload clusters
- **Op√©rations** : Upgrades, backups simplifi√©s (1 seul point de contr√¥le)

---

### Les 2 Composants Essentiels

#### 1Ô∏è‚É£ ClusterAPI Core (CAPI)

**R√¥le :** Framework central pour la gestion d√©clarative de clusters Kubernetes

**Composants install√©s :**
- `capi-controller-manager` : Orchestrateur principal (Cluster, Machine CRDs)
- `capi-kubeadm-bootstrap-controller` : Bootstrap nodes avec kubeadm
- `capi-kubeadm-control-plane-controller` : Gestion control planes HA

**Version :** v1.10.6

---

#### 2Ô∏è‚É£ Docker Provider (CAPD)

**R√¥le :** Provider d'infrastructure pour cr√©er des clusters locaux avec Docker

**Pourquoi Docker Provider ?**
- **Vitesse** : Clusters en 2-3 minutes (vs 8-10min avec cloud VMs)
- **Co√ªt z√©ro** : Pas de facture AWS/Azure
- **Id√©al pour** : D√©veloppement, CI/CD, formation, testing

**Composant install√© :**
- `capd-controller-manager` : Cr√©e containers Docker simulant des VMs

**Version :** v1.10.6 (fix√©e pour coh√©rence)

**‚ö†Ô∏è Production :** Remplacer par CAPA (AWS), CAPZ (Azure), CAPG (GCP)

**Note :** Les autres providers (k0smotron, Helm Addon) seront install√©s plus tard, dans les modules o√π ils sont utilis√©s.

---

## üìã Actions Pas-√†-Pas

> **üí° Raccourci :** Pour un setup automatis√© complet, utilisez `./setup.sh` qui ex√©cute toutes les √©tapes ci-dessous. Pour une compr√©hension d√©taill√©e, suivez les √©tapes manuelles.

### √âtape 1 : V√©rifier que les outils sont install√©s

**Objectif :** Confirmer que Docker, kind, kubectl, clusterctl, helm sont disponibles

**Commande :**
```bash
cd /home/volcampdev/workshop-express/00-setup-management
chmod +x verify-tools.sh
./verify-tools.sh
```

**Explication :**
- Script bash qui teste chaque outil requis
- `command -v` : V√©rifie si la commande existe dans PATH
- Affiche la version pour confirmation

**R√©sultat attendu :**
```
üîç V√©rification des outils...
‚úÖ docker: Docker version 27.4.0
‚úÖ kind: kind v0.30.0
‚úÖ kubectl: Client Version: v1.32.0
‚úÖ clusterctl: v1.10.6
‚úÖ helm: v3.19.0

‚úÖ Tous les outils sont pr√™ts!
```

**‚ùå Si un outil manque :** Retourner au Module 00-introduction pour l'installer

---

### √âtape 2 : Cr√©er le cluster de management avec kind

**Objectif :** Cr√©er un cluster Kubernetes local qui h√©bergera ClusterAPI

**Commande :**
```bash
kind create cluster --config management-cluster-config.yaml
```

**Fichier de configuration :** Le fichier `management-cluster-config.yaml` est disponible dans le r√©pertoire du module.

**Explication de la configuration :**

**1. Nom du cluster :**
```yaml
name: capi-management
```
- Identifie le cluster (contexte kubectl sera `kind-capi-management`)

**2. Montage socket Docker :**
```yaml
extraMounts:
  - hostPath: /var/run/docker.sock
    containerPath: /var/run/docker.sock
```
- **ESSENTIEL** : Monte la socket Docker de l'h√¥te dans le container kind
- Permet au Docker Provider (CAPD) de cr√©er des containers pour les workload clusters
- Sans cela, CAPD ne peut pas communiquer avec le daemon Docker

**3. Port mapping 30080 :**
```yaml
extraPortMappings:
  - containerPort: 30080
    hostPort: 30080
```
- Expose le port 30080 du container kind vers localhost
- N√©cessaire pour tester les applications d√©ploy√©es (nginx, etc.)
- Dans les modules suivants, vous acc√©derez √† http://localhost:30080

**4. Labels du node :**
```yaml
node-labels: "ingress-ready=true"
```
- Marque le node comme pr√™t pour ingress controllers
- Utilis√© par les applications avec LoadBalancer/Ingress

**5. Authorization mode :**
```yaml
authorization-mode: "Webhook"
```
- Active les webhooks d'admission
- Requis par cert-manager et autres controllers avanc√©s

**R√©sultat attendu :**
```
Creating cluster "capi-management" ...
 ‚úì Ensuring node image (kindest/node:v1.32.0)
 ‚úì Preparing nodes
 ‚úì Writing configuration
 ‚úì Starting control-plane
 ‚úì Installing CNI
 ‚úì Installing StorageClass
Set kubectl context to "kind-capi-management"
You can now use your cluster with:

kubectl cluster-info --context kind-capi-management
```

**‚úÖ V√©rification :**
```bash
kubectl cluster-info --context kind-capi-management
kubectl get nodes
```

Vous devriez voir :
```
NAME                            STATUS   ROLES           AGE   VERSION
capi-management-control-plane   Ready    control-plane   1m    v1.32.0
```

---

### √âtape 3 : Initialiser ClusterAPI avec le Docker Provider

**Objectif :** Installer les controllers ClusterAPI dans le management cluster

**Commande :**
```bash
export CLUSTER_TOPOLOGY=true
export EXP_CLUSTER_RESOURCE_SET=true
clusterctl init --infrastructure docker:v1.10.6
```

**Explication de la commande :**
- `export CLUSTER_TOPOLOGY=true` : Active la feature gate Cluster Topology (ClusterClass)
- `export EXP_CLUSTER_RESOURCE_SET=true` : Active la feature gate ClusterResourceSet (installation automatique d'addons)
- `clusterctl init` : Commande d'initialisation ClusterAPI
- `--infrastructure docker:v1.10.6` : Sp√©cifie le provider (CAPD) avec version fixe v1.10.6
- Installe automatiquement :
  - ClusterAPI Core v1.10.6
  - Kubeadm Bootstrap Provider v1.10.6
  - Kubeadm Control Plane Provider v1.10.6
  - Docker Infrastructure Provider v1.10.6
  - cert-manager (d√©pendance requise)

**R√©sultat attendu :**
```
Fetching providers
Installing cert-manager Version="v1.18.2"
Waiting for cert-manager to be available...
Installing Provider="cluster-api" Version="v1.10.6" TargetNamespace="capi-system"
Installing Provider="bootstrap-kubeadm" Version="v1.10.6" TargetNamespace="capi-kubeadm-bootstrap-system"
Installing Provider="control-plane-kubeadm" Version="v1.10.6" TargetNamespace="capi-kubeadm-control-plane-system"
Installing Provider="infrastructure-docker" Version="v1.10.6" TargetNamespace="capd-system"

Your management cluster has been initialized successfully!

You can now create your first workload cluster by running the following:

  clusterctl generate cluster [name] --infrastructure docker | kubectl apply -f -
```

**‚è≥ Temps d'installation :** 1-2 minutes

**‚úÖ V√©rification :**
```bash
kubectl get pods -A | grep -E "(capi|cert-manager)"
```

**R√©sultat attendu :**
```
NAMESPACE                          NAME                                                            READY   STATUS
cert-manager                       cert-manager-xxx                                                1/1     Running
cert-manager                       cert-manager-cainjector-xxx                                     1/1     Running
cert-manager                       cert-manager-webhook-xxx                                        1/1     Running
capi-kubeadm-bootstrap-system      capi-kubeadm-bootstrap-controller-manager-xxx                   1/1     Running
capi-kubeadm-control-plane-system  capi-kubeadm-control-plane-controller-manager-xxx               1/1     Running
capi-system                        capi-controller-manager-xxx                                     1/1     Running
capd-system                        capd-controller-manager-xxx                                     1/1     Running
```

**üîç 5 namespaces cr√©√©s = 5 controllers** :
1. **cert-manager** : Gestion automatique certificats TLS
2. **capi-system** : Controller principal ClusterAPI
3. **capi-kubeadm-bootstrap-system** : Bootstrap nodes avec kubeadm
4. **capi-kubeadm-control-plane-system** : Gestion control planes
5. **capd-system** : Docker infrastructure provider

---

### √âtape 4 : V√©rifier le montage de la socket Docker

**Objectif :** Confirmer que CAPD peut communiquer avec Docker pour cr√©er des workload clusters

**Commande :**
```bash
./verify-docker-socket.sh
```

**R√©sultat attendu :**
```
üîç V√©rification du montage de la socket Docker
===============================================

‚úÖ Cluster kind 'capi-management' existe

üîß Test d'acc√®s √† la socket Docker depuis le cluster kind...

‚úÖ Socket Docker est mont√©e et accessible: /var/run/docker.sock
   Permissions: srw-rw---- root docker

üê≥ Test de connectivit√© Docker depuis le cluster kind...

‚úÖ Communication avec Docker Daemon r√©ussie
   Containers visibles: 2

üéõÔ∏è  V√©rification CAPD Controller...

‚úÖ Namespace capd-system existe
‚úÖ CAPD Controller est Running (1/1)

   V√©rification des logs CAPD pour erreurs Docker...
   ‚úÖ Aucune erreur Docker dans les logs CAPD

===============================================
üéâ V√©rification termin√©e avec succ√®s!

üìä R√©sum√©:
  ‚úÖ Socket Docker mont√©e: /var/run/docker.sock
  ‚úÖ Communication Docker fonctionnelle
  ‚úÖ CAPD peut cr√©er des containers pour workload clusters

üöÄ Le cluster de management est pr√™t √† cr√©er des workload clusters!
```

---

### √âtape 5 : V√©rification finale compl√®te

**Objectif :** Confirmer que tous les composants sont op√©rationnels

**Commande :**
```bash
./validation.sh
```

**R√©sultat attendu :**
```
üîç Module 00-setup: Validation Cluster de Management
====================================================

‚úÖ Cluster de management kind existe: capi-management
‚úÖ Contexte kubectl correctement configur√©: kind-capi-management
‚úÖ ClusterAPI Core install√© (capi-system)
‚úÖ Docker Provider install√© (capd-system)
‚úÖ cert-manager op√©rationnel
‚úÖ Tous les pods sont Running

üìä R√©sum√© des Composants:
  ‚úÖ ClusterAPI: v1.10.6
  ‚úÖ Docker Provider: Op√©rationnel
  ‚úÖ cert-manager: v1.18.2

====================================================
üéâ Module 00-setup termin√© avec succ√®s!
üöÄ Management cluster pr√™t √† cr√©er des workload clusters
====================================================

Prochaine commande:
  cd ../01-premier-cluster
  cat commands.md
```

**‚úÖ Tous les tests passent :** Votre management cluster est pr√™t !

---

### √âtape 6 : Explorer les ressources install√©es

**Objectif :** Comprendre ce qui a √©t√© install√©

**Commandes d'exploration :**

**6.1 - Voir tous les namespaces cr√©√©s**
```bash
kubectl get namespaces | grep -E "(capi|cert-manager)"
```

**R√©sultat :**
```
capi-kubeadm-bootstrap-system      Active   10m
capi-kubeadm-control-plane-system  Active   10m
capi-system                        Active   10m
capd-system                        Active   10m
cert-manager                       Active   10m
```

---

**6.2 - Voir les CRDs (Custom Resource Definitions) install√©es**
```bash
kubectl get crds | grep cluster.x-k8s.io
```

**R√©sultat :**
```
clusters.cluster.x-k8s.io
dockerclusters.infrastructure.cluster.x-k8s.io
dockermachines.infrastructure.cluster.x-k8s.io
dockermachinetemplates.infrastructure.cluster.x-k8s.io
kubeadmconfigs.bootstrap.cluster.x-k8s.io
kubeadmconfigtemplates.bootstrap.cluster.x-k8s.io
kubeadmcontrolplanes.controlplane.cluster.x-k8s.io
machinedeployments.cluster.x-k8s.io
machines.cluster.x-k8s.io
...
```

**üîç Ces CRDs sont les "types" que vous utiliserez** dans les modules suivants (Cluster, Machine, etc.)

---

**6.3 - V√©rifier les versions install√©es**
```bash
clusterctl version
kubectl get deployment -n capi-system capi-controller-manager -o jsonpath='{.spec.template.spec.containers[0].image}'
```

**R√©sultat :**
```
clusterctl version: &version.Info{Major:"1", Minor:"11", GitVersion:"v1.10.6"}
registry.k8s.io/cluster-api/cluster-api-controller:v1.10.6
```

---

**6.4 - Explorer les pods de chaque composant**
```bash
kubectl get pods -n capi-system
kubectl get pods -n capd-system
kubectl get pods -n cert-manager
```

---

**6.5 - V√©rifier que la socket Docker est accessible**
```bash
# Tester depuis le container kind
docker exec capi-management-control-plane docker ps

# Devrait afficher tous les containers Docker de l'h√¥te
```

---

## üéì Points Cl√©s √† Retenir

‚úÖ **Management Cluster** : Usine √† clusters, h√©berge les controllers ClusterAPI
‚úÖ **ClusterAPI Core** : Framework d√©claratif (Cluster, Machine CRDs)
‚úÖ **Docker Provider** : Infrastructure locale rapide (dev/test)
‚úÖ **cert-manager** : Gestion automatique certificats (d√©pendance CAPI)
‚úÖ **Autres providers** : k0smotron et Helm Addon seront install√©s dans les modules suivants

### Architecture R√©capitulative

```
Management Cluster (kind)
‚îÇ
‚îú‚îÄ‚îÄ ClusterAPI Core (capi-system)
‚îÇ   ‚îú‚îÄ‚îÄ cluster-controller      ‚Üí G√®re objets Cluster
‚îÇ   ‚îú‚îÄ‚îÄ machine-controller      ‚Üí G√®re objets Machine
‚îÇ   ‚îî‚îÄ‚îÄ machinedeployment-controller ‚Üí G√®re scaling workers
‚îÇ
‚îú‚îÄ‚îÄ Bootstrap Provider (capi-kubeadm-bootstrap-system)
‚îÇ   ‚îî‚îÄ‚îÄ kubeadm-bootstrap-controller ‚Üí Configure nodes avec kubeadm
‚îÇ
‚îú‚îÄ‚îÄ Control Plane Provider (capi-kubeadm-control-plane-system)
‚îÇ   ‚îî‚îÄ‚îÄ kubeadmcontrolplane-controller ‚Üí G√®re control planes HA
‚îÇ
‚îú‚îÄ‚îÄ Infrastructure Provider
‚îÇ   ‚îî‚îÄ‚îÄ Docker Provider (capd-system) ‚Üí Cr√©e containers
‚îÇ
‚îî‚îÄ‚îÄ Dependencies
    ‚îî‚îÄ‚îÄ cert-manager ‚Üí Certificats TLS automatiques
```

---

## ‚è≠Ô∏è Prochaine √âtape

Management cluster ‚úÖ pr√™t, passez au **Module 01** :

```bash
cd ../01-premier-cluster
cat commands.md
```

**Module 01 :** Cr√©er votre premier workload cluster avec Docker Provider

---

## üí° Comprendre en Profondeur

> **Note :** Cette section approfondit les concepts techniques. Vous pouvez la sauter et y revenir plus tard.

### Pourquoi kind pour le Management Cluster ?

**kind (Kubernetes IN Docker)** est le choix id√©al pour workshops/dev car :

**Avantages :**
- **Setup rapide** : < 1 minute vs 10-15min cloud clusters
- **Co√ªt z√©ro** : Pas de facture AWS/Azure
- **Reproductible** : Configuration identique sur tous les laptops
- **Cleanup facile** : `kind delete cluster` = tout supprim√©
- **CI/CD friendly** : Parfait pour pipelines automatis√©s

**Limitations (production) :**
- Pas de persistance r√©elle (tout en RAM/disk local)
- Pas de HA multi-nodes physiques
- Pas de load balancing cloud
- Limit√© par ressources de la machine h√¥te

**Production Management Cluster :**
```
Environment          Recommendation
‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
Dev/Test            ‚Üí kind
CI/CD               ‚Üí kind ou EKS/GKE
Staging             ‚Üí EKS, AKS, GKE (HA)
Production          ‚Üí EKS, AKS, GKE (HA + backup)
```

---

### Anatomie d'un Cluster kind

**Quand vous ex√©cutez `kind create cluster` :**

```bash
docker ps
```

Vous voyez :
```
CONTAINER ID   IMAGE                  NAMES
abc123def456   kindest/node:v1.32.0   capi-management-control-plane
```

**Ce container contient un Kubernetes COMPLET :**
- **Control Plane** : API server, etcd, scheduler, controller-manager
- **Kubelet** : Agent node
- **Container Runtime** : containerd
- **CNI** : kindnet (r√©seau pod)

**Structure interne :**
```
Container kind (Docker)
‚îú‚îÄ‚îÄ systemd (init system)
‚îú‚îÄ‚îÄ containerd (runtime pour pods)
‚îú‚îÄ‚îÄ kubelet (agent Kubernetes)
‚îî‚îÄ‚îÄ Static Pods (dans /etc/kubernetes/manifests/)
    ‚îú‚îÄ‚îÄ kube-apiserver
    ‚îú‚îÄ‚îÄ kube-controller-manager
    ‚îú‚îÄ‚îÄ kube-scheduler
    ‚îî‚îÄ‚îÄ etcd
```

**Socket Docker Mont√©e - Architecture Critique :**
```yaml
extraMounts:
  - hostPath: /var/run/docker.sock
    containerPath: /var/run/docker.sock
```

**Pourquoi c'est ESSENTIEL :**
```
Host Machine
‚îú‚îÄ‚îÄ Docker Daemon (dockerd)
‚îÇ   ‚îî‚îÄ‚îÄ Socket: /var/run/docker.sock
‚îÇ
‚îú‚îÄ‚îÄ Container kind (management cluster)
‚îÇ   ‚îú‚îÄ‚îÄ Socket mont√©e: /var/run/docker.sock ‚Üí (partag√©e avec host)
‚îÇ   ‚îî‚îÄ‚îÄ Pod CAPD Controller
‚îÇ       ‚îî‚îÄ‚îÄ Utilise la socket pour cr√©er containers (workload cluster nodes)
‚îÇ
‚îî‚îÄ‚îÄ Containers cr√©√©s par CAPD (workload clusters)
    ‚îú‚îÄ‚îÄ dev-cluster-control-plane-xxx
    ‚îú‚îÄ‚îÄ dev-cluster-worker-xxx
    ‚îî‚îÄ‚îÄ k0s-demo-cluster-worker-xxx
```

**Flow de cr√©ation d'un workload cluster :**
```
1. User: kubectl apply -f dev-cluster.yaml
   ‚Üì
2. CAPI Controller (dans kind): D√©tecte nouveau Cluster
   ‚Üì
3. CAPD Controller (dans kind): Re√ßoit DockerMachine √† cr√©er
   ‚Üì
4. CAPD utilise /var/run/docker.sock pour communiquer avec Docker host
   ‚Üì
5. Docker Daemon (host): Cr√©e containers (nodes du workload cluster)
   ‚Üì
6. Containers cr√©√©s: Apparaissent dans `docker ps` sur le host
```

**Sans le montage de la socket :**
- CAPD ne peut pas cr√©er de containers
- Les machines restent en "Provisioning" ind√©finiment
- Erreur: "Cannot connect to Docker daemon"

---

**Port Mapping Expliqu√© :**
```yaml
extraPortMappings:
  - containerPort: 30080
    hostPort: 30080
```

**Flow de trafic :**
```
Browser (localhost:30080)
    ‚Üì
Docker Host (port 30080)
    ‚Üì
kind Container (port 30080)
    ‚Üì
Service NodePort (port 30080)
    ‚Üì
Pod Application (port 80)
```

---

### ClusterAPI Init : Que se passe-t-il ?

**Commande :**
```bash
clusterctl init --infrastructure docker
```

**Workflow d√©taill√© :**

**1. V√©rification pr√©requis (T+0s)**
```
clusterctl v√©rifie:
‚úì kubectl accessible
‚úì Cluster Kubernetes d√©tect√© (management cluster)
‚úì Permissions suffisantes (cluster-admin)
```

**2. Installation cert-manager (T+5s)**
```
Why cert-manager first?
‚Üí ClusterAPI utilise webhooks (admission, conversion)
‚Üí Webhooks n√©cessitent certificats TLS
‚Üí cert-manager g√©n√®re/renouvelle automatiquement les certs

Installation:
kubectl apply -f https://github.com/cert-manager/cert-manager/releases/download/v1.18.2/cert-manager.yaml
```

**3. Installation ClusterAPI Core (T+30s)**
```
Namespace: capi-system
Deployment: capi-controller-manager

Controllers inclus:
- Cluster controller (g√®re Cluster CRD)
- Machine controller (g√®re Machine CRD)
- MachineSet controller (g√®re r√©plication)
- MachineDeployment controller (g√®re scaling/updates)
- ClusterResourceSet controller (g√®re addons)
```

**4. Installation Bootstrap Provider (T+45s)**
```
Namespace: capi-kubeadm-bootstrap-system
Deployment: capi-kubeadm-bootstrap-controller-manager

R√¥le:
- G√©n√®re cloud-init scripts pour nodes
- Configure kubeadm init/join automatiquement
- Injecte certificats et tokens
```

**5. Installation Control Plane Provider (T+60s)**
```
Namespace: capi-kubeadm-control-plane-system
Deployment: capi-kubeadm-control-plane-controller-manager

R√¥le:
- G√®re KubeadmControlPlane CRD
- Automatise HA control planes
- Rolling upgrades control planes
- Gestion quorum etcd
```

**6. Installation Docker Provider (T+75s)**
```
Namespace: capd-system
Deployment: capd-controller-manager

R√¥le:
- Cr√©e containers Docker pour simuler VMs
- Configure r√©seau Docker entre containers
- G√®re DockerCluster, DockerMachine CRDs
```

**V√©rification finale :**
```bash
kubectl get pods -A | grep -E "(capi|cert)"
```

**Tous les pods doivent √™tre Running (STATUS) et READY (1/1 ou 2/2)**

---


### cert-manager : Pourquoi Indispensable ?

**ClusterAPI utilise des Webhooks Kubernetes :**

**1. Validating Webhooks** : Valident les objets avant cr√©ation
```yaml
Exemple: Cr√©ation d'un Cluster
User: kubectl apply -f cluster.yaml
    ‚Üì
API Server: Appelle Validating Webhook
    ‚Üì
ClusterAPI Controller: V√©rifie
  ‚úì clusterNetwork.pods.cidrBlocks valide
  ‚úì controlPlaneRef existe
  ‚úì infrastructureRef existe
    ‚Üì
API Server: Accepte ou rejette
```

**2. Mutating Webhooks** : Modifient les objets automatiquement
```yaml
Exemple: Cr√©ation d'une Machine
User: kubectl apply -f machine.yaml (sans spec.version)
    ‚Üì
API Server: Appelle Mutating Webhook
    ‚Üì
ClusterAPI Controller: Injecte automatiquement
  spec.version: v1.32.8 (depuis Cluster parent)
    ‚Üì
Objet modifi√© sauvegard√©
```

**3. Conversion Webhooks** : Convertissent entre versions API
```yaml
Manifest ancien: apiVersion: cluster.x-k8s.io/v1alpha3
    ‚Üì
Conversion Webhook: Convertit v1alpha3 ‚Üí v1beta1
    ‚Üì
Stored version: v1beta1
```

**Webhooks N√âCESSITENT TLS :**
- API server communique avec webhooks via HTTPS
- Sans certificats valides = erreur webhook call failed

**cert-manager automatise :**
```
1. G√©n√®re CA (Certificate Authority) priv√©e
2. Cr√©e certificats pour chaque webhook
3. Injecte caBundle dans webhook configurations
4. Renouvelle automatiquement avant expiration (90 jours)
```

**Sans cert-manager :**
```bash
# G√©n√©ration manuelle (complexe, erreur-prone)
openssl genrsa -out ca.key 2048
openssl req -x509 -new -nodes -key ca.key -subj "/CN=webhook-ca" -days 3650 -out ca.crt
openssl genrsa -out webhook.key 2048
openssl req -new -key webhook.key -subj "/CN=webhook.capi-system.svc" -out webhook.csr
openssl x509 -req -in webhook.csr -CA ca.crt -CAkey ca.key -CAcreateserial -out webhook.crt -days 365
kubectl create secret tls webhook-cert --cert=webhook.crt --key=webhook.key -n capi-system
# ... r√©p√©ter pour chaque webhook
# ... renouvellement manuel tous les ans
```

**Avec cert-manager :**
```yaml
apiVersion: cert-manager.io/v1
kind: Certificate
metadata:
  name: capi-webhook-cert
spec:
  secretName: capi-webhook-cert
  duration: 8760h  # 1 an
  renewBefore: 720h  # Renouveler 30 jours avant
  issuerRef:
    name: capi-selfsigned-issuer
    kind: Issuer
  dnsNames:
    - webhook.capi-system.svc
    - webhook.capi-system.svc.cluster.local
```

**R√©sultat :** Automatis√©, s√©curis√©, sans intervention humaine.

---

## üîß D√©pannage

### Socket Docker Non Mont√©e

**Sympt√¥me :** Dans les modules suivants, les workload clusters ne se cr√©ent pas (machines restent en Provisioning)

**Cause :** Socket Docker (`/var/run/docker.sock`) non mont√©e dans le cluster kind

**Diagnostic :**
```bash
# V√©rifier si la socket est accessible depuis le cluster kind
docker exec capi-management-control-plane ls -la /var/run/docker.sock

# V√©rifier que les pods CAPD peuvent communiquer avec Docker
kubectl logs -n capd-system deployment/capd-controller-manager | grep -i "docker"
```

**Solution :**
```bash
# Recr√©er le cluster avec la socket Docker mont√©e
kind delete cluster --name capi-management

# Le fichier management-cluster-config.yaml est dans le r√©pertoire du module
kind create cluster --config management-cluster-config.yaml
export CLUSTER_TOPOLOGY=true
export EXP_CLUSTER_RESOURCE_SET=true
clusterctl init --infrastructure docker:v1.10.6
```

**V√©rification :**
```bash
# Tester l'acc√®s Docker depuis le cluster
kubectl run -it --rm debug --image=docker:latest --restart=Never -- docker ps

# Vous devriez voir les containers Docker de l'h√¥te
```

---

### ClusterAPI Init √âchoue

**Sympt√¥me :** `clusterctl init` timeout ou erreur

**Diagnostic :**
```bash
# V√©rifier permissions kubectl
kubectl auth can-i create namespaces
kubectl auth can-i create crds

# V√©rifier connexion internet (t√©l√©chargement manifests)
curl -I https://github.com

# Logs de clusterctl
clusterctl init --infrastructure docker -v 5  # Verbosity max
```

**Solutions :**
```bash
# Permissions insuffisantes
kubectl config view --minify  # V√©rifier le contexte actuel
# Utiliser admin kubeconfig ou accorder cluster-admin

# Network issues
# Utiliser --config pour sp√©cifier mirrors locaux
clusterctl init --infrastructure docker --config clusterctl.yaml

# Retry avec cleanup
clusterctl delete --infrastructure docker --include-crd
export CLUSTER_TOPOLOGY=true
export EXP_CLUSTER_RESOURCE_SET=true
clusterctl init --infrastructure docker:v1.10.6
```

---


## üìä Validation Compl√®te

### Checklist Finale

**Management Cluster :**
- [ ] Cluster kind "capi-management" existe
- [ ] Contexte kubectl configur√©: `kind-capi-management`
- [ ] Node status: Ready

**ClusterAPI Core :**
- [ ] Namespace `capi-system` existe
- [ ] Deployment `capi-controller-manager` : Running
- [ ] CRDs install√©es : `kubectl get crd | grep cluster.x-k8s.io` montre 20+ CRDs

**Providers :**
- [ ] Docker Provider (capd-system) : Running

**Dependencies :**
- [ ] cert-manager pods : Running (3/3)

**Commande Unique de Validation :**
```bash
# Le script full-check.sh est disponible dans le r√©pertoire du module
chmod +x full-check.sh
./full-check.sh
```

---

## üéì Ce Que Vous Avez Appris

‚úÖ Cr√©er un cluster kind configur√© pour ClusterAPI
‚úÖ Initialiser ClusterAPI avec le Docker Provider
‚úÖ Comprendre l'architecture Management vs Workload
‚úÖ Valider l'installation compl√®te des composants

**Architecture Finale :**
```
Management Cluster (kind) ‚úÖ
‚îú‚îÄ‚îÄ ClusterAPI v1.10.6 ‚úÖ
‚îú‚îÄ‚îÄ Docker Provider ‚úÖ
‚îî‚îÄ‚îÄ cert-manager v1.18.2 ‚úÖ

Pr√™t √† cr√©er ‚Üí Workload Clusters!
(k0smotron et Helm Addon seront install√©s dans les modules suivants)
```

---

**Module 00-setup compl√©t√© ! üéâ**
**Temps √©coul√© :** 15 minutes
**Prochaine √©tape :** Module 01 - Premier Cluster avec Docker Provider
