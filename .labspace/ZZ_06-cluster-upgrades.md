# Module 06: Mise √† Jour Simultan√©e de Multiples Clusters

**Dur√©e:** 15 minutes
**Objectif:** Mettre √† jour simultan√©ment la version Kubernetes de plusieurs clusters

---

## üìë Table des Mati√®res

- [üéØ Objectifs & Concepts](#-objectifs--concepts)
- [üìã Actions Pas-√†-Pas](#-actions-pas-√†-pas)
- [üí° Comprendre en Profondeur](#-comprendre-en-profondeur)

---

## üéØ Objectifs & Concepts

### Ce que vous allez apprendre

‚úÖ Mettre √† jour simultan√©ment la version Kubernetes de 3+ clusters
‚úÖ Observer le rolling upgrade des control planes et workers
‚úÖ Comprendre le processus zero-downtime de ClusterAPI
‚úÖ V√©rifier la sant√© des clusters apr√®s upgrade

### Le Principe : Rolling Upgrade Automatis√©

**Analogie :** Imaginez une **flotte de navires** qui doivent passer en r√©vision. Au lieu de les ramener au port un par un (s√©quentiel), vous envoyez des √©quipes de maintenance sur chaque navire simultan√©ment (parall√®le), et chaque √©quipe fait la r√©vision membre par membre sans arr√™ter le navire.

**Ce que ClusterAPI fait automatiquement :**
```
Pour chaque cluster (en parall√®le):
  1. Upgrade Control Plane
     - Drain node 1 ‚Üí Upgrade ‚Üí Rejoin
     - (Si HA) Drain node 2 ‚Üí Upgrade ‚Üí Rejoin
     - (Si HA) Drain node 3 ‚Üí Upgrade ‚Üí Rejoin

  2. Upgrade Workers (rolling)
     - Drain worker 1 ‚Üí Upgrade ‚Üí Rejoin
     - Drain worker 2 ‚Üí Upgrade ‚Üí Rejoin
     - ...

R√©sultat: Tous les clusters upgrad√©s sans downtime
```

**Pourquoi c'est s√ªr ?**
- **Validation automatique** : ClusterAPI v√©rifie la sant√© apr√®s chaque node
- **Rollback possible** : Si √©chec, les anciens nodes restent disponibles
- **Zero-downtime** : Les pods sont d√©plac√©s avant drain (si HA)

---

## üìã Actions Pas-√†-Pas

### √âtape 1 : Aller dans le r√©pertoire du module

**Objectif :** Se positionner dans le dossier de travail

**Commande :**
```bash
cd /home/ubuntu/R_D/CLAUDE_PROJECTS/capi-workshop/workshop-express/06-cluster-upgrades
```

---

### √âtape 2 : V√©rifier les versions actuelles des clusters

**Objectif :** Identifier quels clusters ont besoin d'upgrade

**Commande :**
```bash
kubectl get clusters -o custom-columns="NAME:.metadata.name,CP_VERSION:.spec.controlPlaneRef.name,PHASE:.status.phase"
```

**R√©sultat attendu :**
```
NAME         CP_VERSION                     PHASE
dev-cluster  dev-cluster-control-plane      Provisioned
multi-01     multi-01-control-plane         Provisioned
multi-02     multi-02-control-plane         Provisioned
multi-03     multi-03-control-plane         Provisioned
```

---

### √âtape 3 : Voir les versions Kubernetes actuelles

**Objectif :** Confirmer les versions avant upgrade

**Commande :**
```bash
kubectl get kubeadmcontrolplane,machinedeployment -o custom-columns="NAME:.metadata.name,TYPE:.kind,VERSION:.spec.version,REPLICAS:.spec.replicas,READY:.status.readyReplicas"
```

**R√©sultat attendu :**
```
NAME                           TYPE                   VERSION    REPLICAS  READY
dev-cluster-control-plane      KubeadmControlPlane    v1.32.8    1         1
dev-cluster-md-0               MachineDeployment      v1.32.8    2         2
multi-01-control-plane         KubeadmControlPlane    v1.32.8    1         1
multi-01-md-0                  MachineDeployment      v1.32.8    2         2
multi-02-control-plane         KubeadmControlPlane    v1.32.8    1         1
multi-02-md-0                  MachineDeployment      v1.32.8    2         2
multi-03-control-plane         KubeadmControlPlane    v1.32.8    1         1
multi-03-md-0                  MachineDeployment      v1.32.8    2         2
```

**üîç Points cl√©s :**
- Tous les clusters sont sur v1.32.8
- Nous allons upgrader vers v1.33.0 (exemple)
- CP et workers doivent √™tre upgrad√©s s√©par√©ment

---

### √âtape 4 : Examiner le script d'upgrade automatis√©

**Objectif :** Comprendre le workflow d'upgrade

**Commande :**
```bash
cat upgrade-clusters.sh
```

**R√©sultat attendu :**
```bash
#!/bin/bash
# Upgrade multiple clusters to a new Kubernetes version

NEW_VERSION="v1.33.0"  # Target version
CLUSTERS=("dev-cluster" "multi-01" "multi-02" "multi-03")

for cluster in "${CLUSTERS[@]}"; do
  echo "üîÑ Upgrading cluster: $cluster to $NEW_VERSION"

  # Upgrade Control Plane
  kubectl patch kubeadmcontrolplane ${cluster}-control-plane \
    --type=merge \
    -p "{\"spec\":{\"version\":\"${NEW_VERSION}\"}}"

  # Upgrade Workers
  kubectl patch machinedeployment ${cluster}-md-0 \
    --type=merge \
    -p "{\"spec\":{\"template\":{\"spec\":{\"version\":\"${NEW_VERSION}\"}}}}"
done
```

**üîç Explication :**
- Boucle sur tous les clusters
- Patch le KubeadmControlPlane (CP upgrade)
- Patch le MachineDeployment (workers upgrade)
- Les upgrades d√©marrent EN PARALL√àLE pour tous les clusters

---

### √âtape 5 : Lancer l'upgrade simultan√©

**Objectif :** Upgrader tous les clusters en une seule commande

**‚ö†Ô∏è IMPORTANT :** Pour ce workshop, nous allons faire un upgrade "fictif" en changeant juste un label, car v1.33.0 n'existe pas encore. En production, vous changeriez r√©ellement la version.

**Commande (simulation d'upgrade) :**
```bash
# Simulation: On va juste ajouter un label upgrade-test pour voir le rolling update
for cluster in dev-cluster multi-01 multi-02 multi-03; do
  echo "üîÑ Simulating upgrade for cluster: $cluster"
  kubectl patch kubeadmcontrolplane ${cluster}-control-plane \
    --type=merge \
    -p '{"metadata":{"labels":{"upgrade-test":"simulated"}}}'
done
```

**R√©sultat attendu :**
```
üîÑ Simulating upgrade for cluster: dev-cluster
kubeadmcontrolplane.controlplane.cluster.x-k8s.io/dev-cluster-control-plane patched

üîÑ Simulating upgrade for cluster: multi-01
kubeadmcontrolplane.controlplane.cluster.x-k8s.io/multi-01-control-plane patched

üîÑ Simulating upgrade for cluster: multi-02
kubeadmcontrolplane.controlplane.cluster.x-k8s.io/multi-02-control-plane patched

üîÑ Simulating upgrade for cluster: multi-03
kubeadmcontrolplane.controlplane.cluster.x-k8s.io/multi-03-control-plane patched
```

**üîç Ce qui se passerait avec un vrai upgrade :**
1. ClusterAPI d√©tecte le changement de version
2. Pour chaque cluster (en parall√®le):
   - Cr√©e une nouvelle Machine avec la nouvelle version
   - Drain l'ancienne Machine (d√©place les pods)
   - Supprime l'ancienne Machine
   - R√©p√®te pour chaque worker

---

### √âtape 6 : Observer un vrai upgrade (demo avec version patch)

**Objectif :** Voir le rolling upgrade en action

**‚ö†Ô∏è Cette √©tape est optionnelle et d√©pend des versions disponibles.**

**Commande (upgrade patch version) :**
```bash
# Example: upgrade de v1.32.8 vers v1.32.9 (si disponible)
NEW_VERSION="v1.32.9"

# Upgrade un seul cluster pour observer
kubectl patch kubeadmcontrolplane multi-01-control-plane \
  --type=merge \
  -p "{\"spec\":{\"version\":\"${NEW_VERSION}\"}}"
```

**Observer le rolling upgrade :**
```bash
watch -n 2 'kubectl get machines -l cluster.x-k8s.io/cluster-name=multi-01'
```

**R√©sultat attendu (progression) :**

**T+0s - Upgrade d√©marre :**
```
NAME                              CLUSTER    PHASE     VERSION
multi-01-control-plane-xxx        multi-01   Running   v1.32.8
multi-01-md-0-yyy-zzz             multi-01   Running   v1.32.8
multi-01-md-0-yyy-aaa             multi-01   Running   v1.32.8
```

**T+30s - Nouvelle Machine CP cr√©√©e :**
```
NAME                              CLUSTER    PHASE         VERSION
multi-01-control-plane-xxx        multi-01   Running       v1.32.8
multi-01-control-plane-new        multi-01   Provisioning  v1.32.9  ‚Üê Nouveau!
multi-01-md-0-yyy-zzz             multi-01   Running       v1.32.8
multi-01-md-0-yyy-aaa             multi-01   Running       v1.32.8
```

**T+2min - CP upgrad√©, workers en cours :**
```
NAME                              CLUSTER    PHASE         VERSION
multi-01-control-plane-new        multi-01   Running       v1.32.9  ‚Üê Upgrad√©!
multi-01-md-0-yyy-zzz             multi-01   Running       v1.32.8
multi-01-md-0-yyy-aaa             multi-01   Running       v1.32.8
multi-01-md-0-new1                multi-01   Provisioning  v1.32.9  ‚Üê Nouveau!
```

**T+5min - Upgrade complet :**
```
NAME                              CLUSTER    PHASE     VERSION
multi-01-control-plane-new        multi-01   Running   v1.32.9
multi-01-md-0-new1                multi-01   Running   v1.32.9
multi-01-md-0-new2                multi-01   Running   v1.32.9
```

**Appuyez sur Ctrl+C pour arr√™ter le watch**

---

### √âtape 7 : Utiliser le script de monitoring

**Objectif :** Surveiller l'upgrade de tous les clusters en parall√®le

**Commande :**
```bash
./monitor-upgrades.sh
```

**R√©sultat attendu :**
```
üîç Monitoring Cluster Upgrades
================================

Cluster: dev-cluster
  Control Plane: v1.32.8 (1/1 ready)
  Workers: v1.32.8 (2/2 ready)
  Status: ‚úÖ Stable

Cluster: multi-01
  Control Plane: v1.32.9 (1/1 ready)  ‚Üê Upgrad√©!
  Workers: v1.32.9 (2/2 ready)
  Status: ‚úÖ Upgraded

Cluster: multi-02
  Control Plane: v1.32.8 ‚Üí v1.32.9 (0/1 ready)  ‚Üê En cours
  Workers: v1.32.8 (2/2 ready)
  Status: üîÑ Upgrading

Cluster: multi-03
  Control Plane: v1.32.8 (1/1 ready)
  Workers: v1.32.8 (2/2 ready)
  Status: ‚è≥ Pending

Press Ctrl+C to exit
```

---

### √âtape 8 : V√©rifier les versions apr√®s upgrade

**Objectif :** Confirmer que les upgrades ont r√©ussi

**Commande :**
```bash
kubectl get kubeadmcontrolplane,machinedeployment \
  -o custom-columns="NAME:.metadata.name,VERSION:.spec.version,READY:.status.readyReplicas,UPDATED:.status.updatedReplicas"
```

**R√©sultat attendu (si upgrade r√©el) :**
```
NAME                           VERSION    READY  UPDATED
dev-cluster-control-plane      v1.33.0    1      1
dev-cluster-md-0               v1.33.0    2      2
multi-01-control-plane         v1.33.0    1      1
multi-01-md-0                  v1.33.0    2      2
multi-02-control-plane         v1.33.0    1      1
multi-02-md-0                  v1.33.0    2      2
multi-03-control-plane         v1.33.0    1      1
multi-03-md-0                  v1.33.0    2      2
```

**‚úÖ V√©rification :**
- VERSION = nouvelle version
- READY = UPDATED (toutes les machines upgrad√©es)

---

### √âtape 9 : V√©rifier la sant√© des workload clusters

**Objectif :** Confirmer que les applications tournent toujours

**Commandes :**
```bash
# V√©rifier les nodes de chaque cluster
for cluster in dev-cluster multi-01 multi-02 multi-03; do
  echo "=== Cluster: $cluster ==="
  kubectl --kubeconfig ${cluster}.kubeconfig get nodes
  echo ""
done
```

**R√©sultat attendu (pour chaque cluster) :**
```
=== Cluster: multi-01 ===
NAME                          STATUS   ROLES           AGE   VERSION
multi-01-control-plane-new    Ready    control-plane   5m    v1.33.0
multi-01-md-0-new1            Ready    <none>          3m    v1.33.0
multi-01-md-0-new2            Ready    <none>          3m    v1.33.0
```

**‚úÖ V√©rification :**
- STATUS = Ready
- VERSION = nouvelle version
- Aucun node en NotReady

---

### √âtape 10 : Tester les applications (si deploy√©es)

**Objectif :** Confirmer que les apps survivent √† l'upgrade

**Si nginx d√©ploy√© (Module 05) :**
```bash
# V√©rifier que nginx tourne toujours
for cluster in multi-01 multi-02 multi-03; do
  echo "=== Cluster: $cluster ==="
  kubectl --kubeconfig ${cluster}.kubeconfig get pods -n nginx
done
```

**R√©sultat attendu :**
```
=== Cluster: multi-01 ===
NAME                     READY   STATUS    RESTARTS   AGE
nginx-xxxxx-yyyyy        1/1     Running   0          15m
nginx-xxxxx-zzzzz        1/1     Running   0          15m
```

**‚úÖ V√©rification :**
- Pods en Running
- RESTARTS = 0 (pas de crash pendant l'upgrade)
- AGE plus ancien que l'upgrade (pods pas recr√©√©s)

---

### √âtape 11 : Analyser les √©v√©nements d'upgrade

**Objectif :** Comprendre ce qui s'est pass√© en d√©tail

**Commande :**
```bash
kubectl get events --sort-by='.lastTimestamp' | grep -E 'Machine|upgrade' | tail -20
```

**R√©sultat attendu :**
```
5m  Normal  SuccessfulCreate  Machine  Created new machine multi-01-control-plane-new
4m  Normal  Draining          Machine  Draining node multi-01-control-plane-xxx
3m  Normal  Deleted           Machine  Deleted machine multi-01-control-plane-xxx
2m  Normal  SuccessfulCreate  Machine  Created new machine multi-01-md-0-new1
...
```

**üîç √âtapes visibles :**
1. Create new machine (nouvelle version)
2. Drain old machine (d√©place les pods)
3. Delete old machine
4. Repeat pour chaque node

---

### √âtape 12 : Calculer le temps d'upgrade

**Objectif :** Mesurer la dur√©e totale

**Commande :**
```bash
# Comparer timestamp de d√©but et fin
CLUSTER="multi-01"
START_TIME=$(kubectl get kubeadmcontrolplane ${CLUSTER}-control-plane -o jsonpath='{.metadata.annotations.upgrade-start-time}' 2>/dev/null || echo "N/A")
echo "Upgrade start time: $START_TIME"

# Si pas d'annotation, utiliser les events
kubectl get events --sort-by='.firstTimestamp' | grep "multi-01" | grep "SuccessfulCreate" | head -1
kubectl get events --sort-by='.lastTimestamp' | grep "multi-01" | grep "Running" | tail -1
```

**Temps d'upgrade typiques :**
```
Single cluster (1 CP + 2 workers):
  - Control Plane: 2-3 minutes
  - Workers (s√©quentiel): 2x2 minutes = 4 minutes
  - Total: ~7 minutes

Multiple clusters (parallel):
  - 4 clusters x 7 minutes each = 7 minutes (pas 28!)
  - √âconomie de temps: 75% vs s√©quentiel
```

---

### √âtape 13 : Rollback d'un upgrade (demo)

**Objectif :** Savoir annuler un upgrade probl√©matique

**‚ö†Ô∏è Cette section est th√©orique (ne pas ex√©cuter si upgrade r√©ussi)**

**Commande de rollback :**
```bash
# Rollback vers l'ancienne version
OLD_VERSION="v1.32.8"
CLUSTER="multi-01"

kubectl patch kubeadmcontrolplane ${CLUSTER}-control-plane \
  --type=merge \
  -p "{\"spec\":{\"version\":\"${OLD_VERSION}\"}}"

kubectl patch machinedeployment ${CLUSTER}-md-0 \
  --type=merge \
  -p "{\"spec\":{\"template\":{\"spec\":{\"version\":\"${OLD_VERSION}\"}}}}"
```

**üîç Ce qui se passe :**
- ClusterAPI d√©tecte la version downgrade
- Cr√©e de nouvelles machines avec l'ancienne version
- Rolling update vers l'ancienne version
- Les donn√©es/apps sont pr√©serv√©es

---

### √âtape 14 : Cleanup des anciennes machines

**Objectif :** V√©rifier que les anciennes machines sont supprim√©es

**Commande :**
```bash
# Lister toutes les machines
kubectl get machines -A

# V√©rifier qu'il n'y a pas de machines "Deleting" coinc√©es
kubectl get machines -o json | jq '.items[] | select(.status.phase=="Deleting") | .metadata.name'
```

**R√©sultat attendu :**
- Pas de machines en phase "Deleting"
- Seulement les nouvelles machines en "Running"

**Si machines coinc√©es :**
```bash
# Forcer la suppression (cas rare)
kubectl delete machine <stuck-machine-name> --force --grace-period=0
```

---

### √âtape 15 : Valider le module

**Objectif :** Ex√©cuter le script de validation automatique

**Commande :**
```bash
./validation.sh
```

**R√©sultat attendu :**
```
üîç Module 06: Validation Cluster Upgrades
==========================================

‚úÖ 4 Clusters existent
‚úÖ Tous les clusters sont Provisioned
‚úÖ Tous les control planes sont ready
‚úÖ Toutes les machines sont Running
‚úÖ Aucune machine en phase Deleting
‚úÖ Workload clusters accessibles
‚úÖ Nodes Ready dans tous les clusters

==========================================
üéâ Module 06 termin√© avec succ√®s!
üöÄ Pr√™t pour Module 07: Operations & Cleanup
==========================================
```

---

## üéì Points Cl√©s √† Retenir

‚úÖ **Rolling upgrade automatis√©** : ClusterAPI g√®re le drain/upgrade/rejoin
‚úÖ **Zero-downtime** : Pods d√©plac√©s avant upgrade (si HA)
‚úÖ **Parallel upgrades** : Plusieurs clusters upgrad√©s simultan√©ment
‚úÖ **Rollback possible** : Retour √† l'ancienne version si probl√®me
‚úÖ **Validation automatique** : ClusterAPI v√©rifie la sant√© apr√®s chaque √©tape
‚úÖ **Production-ready** : Pattern utilis√© pour 100+ clusters en prod

### Workflow d'Upgrade D√©taill√©

```
                     ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
                     ‚îÇ  User: Patch    ‚îÇ
                     ‚îÇ  version field  ‚îÇ
                     ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                              ‚îÇ
                              ‚ñº
                     ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
                     ‚îÇ  ClusterAPI     ‚îÇ
                     ‚îÇ  Reconcile Loop ‚îÇ
                     ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                              ‚îÇ
                ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
                ‚îÇ                           ‚îÇ
                ‚ñº                           ‚ñº
       ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê         ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
       ‚îÇ Control Plane  ‚îÇ         ‚îÇ    Workers     ‚îÇ
       ‚îÇ    Upgrade     ‚îÇ         ‚îÇ    Upgrade     ‚îÇ
       ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò         ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                ‚îÇ                           ‚îÇ
    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê   ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
    ‚ñº                       ‚ñº   ‚ñº                       ‚ñº
[Create New]           [Drain]  [Create New]       [Drain]
[Wait Ready]           [Delete] [Wait Ready]       [Delete]
[Delete Old]                    [Next Worker]
```

---

## ‚è≠Ô∏è Prochaine √âtape

**Module 07 (15 min) :** Operations & Cleanup
- Scaler les workers dynamiquement
- Monitorer les ressources
- Cleanup complet de l'environnement

```bash
cd ../07-operations-cleanup
cat commands.md
```

---

## üí° Comprendre en Profondeur

> **Note :** Cette section approfondit les concepts techniques.

### Strat√©gies d'Upgrade

#### Rolling Update (d√©faut)

**Configuration :**
```yaml
spec:
  strategy:
    type: RollingUpdate
    rollingUpdate:
      maxSurge: 1        # 1 nouveau node avant supprimer ancien
      maxUnavailable: 0  # 0 node down autoris√©
```

**Workflow :**
```
3 workers total, maxSurge=1, maxUnavailable=0:

T+0:  [Old1] [Old2] [Old3]           (3 running)
T+1:  [Old1] [Old2] [Old3] [New1]    (4 running - surge)
T+2:  [Old2] [Old3] [New1]           (Old1 drained & deleted)
T+3:  [Old2] [Old3] [New1] [New2]    (4 running - surge)
T+4:  [Old3] [New1] [New2]           (Old2 drained & deleted)
T+5:  [Old3] [New1] [New2] [New3]    (4 running - surge)
T+6:  [New1] [New2] [New3]           (Old3 drained & deleted)

Result: Always 3+ nodes running ‚Üí Zero downtime
```

---

#### In-Place Update (exp√©rimental)

**Avantages :**
- Pas de cr√©ation de nouvelles machines
- Upgrade plus rapide
- Conserve les IP

**D√©savantages :**
- Downtime possible (reboot requis)
- Moins safe (pas de rollback facile)
- Non recommand√© pour prod

---

### Upgrade Control Plane HA

**Pour control plane avec replicas=3 :**

```yaml
spec:
  replicas: 3
  rolloutStrategy:
    type: RollingUpdate
    rollingUpdate:
      maxSurge: 1
```

**Workflow :**
```
T+0:  [CP1] [CP2] [CP3]              (Quorum 3/3)
T+1:  [CP1] [CP2] [CP3] [CP4-new]    (4 running)
T+2:  [CP2] [CP3] [CP4-new]          (Quorum 3/3 - CP1 supprim√©)
T+3:  [CP2] [CP3] [CP4] [CP5-new]    (4 running)
T+4:  [CP3] [CP4] [CP5-new]          (Quorum 3/3 - CP2 supprim√©)
T+5:  [CP3] [CP4] [CP5] [CP6-new]    (4 running)
T+6:  [CP4] [CP5] [CP6]              (Quorum 3/3 - CP3 supprim√©)

Result: Quorum etcd maintenu ‚Üí API server toujours disponible
```

**Points critiques :**
- Toujours maintenir le quorum etcd (n/2 + 1)
- Ne jamais upgrader 2 CP en m√™me temps
- V√©rifier sant√© apr√®s chaque CP

---

### Gestion des Pods Pendant l'Upgrade

**Pod Eviction Process :**

1. **Node marked unschedulable** : Nouveaux pods ne peuvent pas √™tre cr√©√©s
2. **Pods avec PDB v√©rifi√©** : Respect des PodDisruptionBudgets
3. **Graceful termination** : SIGTERM envoy√©, grace period (30s par d√©faut)
4. **Force kill** : Si timeout, SIGKILL envoy√©
5. **Pods recr√©√©s** : Sur d'autres nodes par les controllers (ReplicaSet, etc.)

**Best practices :**
```yaml
# Dans vos Deployments
apiVersion: apps/v1
kind: Deployment
spec:
  replicas: 3  # ‚â•2 pour survivre √† l'upgrade
  template:
    spec:
      containers:
      - name: app
        lifecycle:
          preStop:  # Hook pour cleanup graceful
            exec:
              command: ["/bin/sh", "-c", "sleep 15"]
        terminationGracePeriodSeconds: 30
```

---

### Versionning Kubernetes

**Semantic Versioning :**
```
v1.32.8
‚îÇ ‚îÇ  ‚îî‚îÄ Patch (bugfixes, backports s√©curit√©)
‚îÇ ‚îî‚îÄ‚îÄ‚îÄ‚îÄ Minor (features, API changes)
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ Major (breaking changes - rare)
```

**R√®gles d'upgrade :**
- ‚úÖ Patch upgrade : Toujours safe (v1.32.8 ‚Üí v1.32.9)
- ‚úÖ Minor upgrade : 1 version √† la fois (v1.32 ‚Üí v1.33)
- ‚ùå Skip versions : Non support√© (v1.32 ‚Üí v1.34)
- ‚ùå Downgrade major : Non support√© (v1.33 ‚Üí v1.32)

**Compatibilit√© components :**
```
Control Plane v1.33.0
  ‚îú‚îÄ Workers: v1.32.x ou v1.33.x (N-1 support√©)
  ‚îú‚îÄ kubectl: v1.32.x √† v1.34.x (N-1 √† N+1)
  ‚îî‚îÄ CNI: Compatible toutes versions (Calico, Cilium, etc.)
```

---

### Rollback Scenarios

#### Scenario 1: Upgrade √©choue au milieu

**Sympt√¥mes :**
- Nouvelles machines ne d√©marrent pas
- Old machines toujours Running

**Action :**
```bash
# ClusterAPI rollback automatique apr√®s timeout (10 min)
# Ou manuel :
kubectl patch kubeadmcontrolplane <name> --type=merge -p '{"spec":{"version":"<old-version>"}}'
```

**R√©sultat :**
- Anciennes machines conserv√©es
- Nouvelles machines supprim√©es
- Cluster revient √† l'√©tat stable

---

#### Scenario 2: Upgrade r√©ussit mais app casse

**Sympt√¥mes :**
- Nodes en Ready
- Pods crashent ou comportement anormal

**Actions :**
1. V√©rifier logs des pods
2. Rollback app (pas K8s)
3. Si API incompatibilit√©, rollback K8s

```bash
# Rollback K8s version
kubectl patch kubeadmcontrolplane <name> --type=merge -p '{"spec":{"version":"<old-version>"}}'
```

---

### Monitoring d'Upgrade

**M√©triques cl√©s √† surveiller :**

```bash
# 1. Machine lifecycle
kubectl get machines -w

# 2. Node status
kubectl --kubeconfig workload.kubeconfig get nodes -w

# 3. Pod evictions
kubectl --kubeconfig workload.kubeconfig get events | grep Evicted

# 4. API availability (si HA)
while true; do
  kubectl --kubeconfig workload.kubeconfig get nodes &>/dev/null && echo "‚úÖ API OK" || echo "‚ùå API DOWN"
  sleep 2
done
```

**Alerting production :**
- Prometheus: `kube_node_status_condition{condition="Ready",status="false"}`
- Alert si upgrade prend > 15 minutes
- Alert si pods evicted > threshold

---

### Troubleshooting

#### Upgrade stuck / ne d√©marre pas

**Diagnostic :**
```bash
# Check KubeadmControlPlane status
kubectl describe kubeadmcontrolplane <name>

# Events
kubectl get events --sort-by='.lastTimestamp' | grep <cluster>

# Machine controller logs
kubectl logs -n capi-system deployment/capi-controller-manager -f
```

**Causes fr√©quentes :**
1. Image Docker non disponible pour nouvelle version
2. Ressources insuffisantes
3. Version incompatible (skip de version)
4. Erreur de syntaxe dans le patch

**Solution :**
```bash
# Rollback
kubectl patch kubeadmcontrolplane <name> --type=merge -p '{"spec":{"version":"<old-version>"}}'
```

---

#### Machine reste en Deleting

**Diagnostic :**
```bash
kubectl describe machine <stuck-machine>
```

**Causes :**
- Finalizer bloqu√©
- Provider infrastructure erreur

**Solution :**
```bash
# Remove finalizer
kubectl patch machine <name> -p '{"metadata":{"finalizers":[]}}' --type=merge

# Force delete
kubectl delete machine <name> --force --grace-period=0
```

---

## üéì Ce Que Vous Avez Appris

‚úÖ Upgrader simultan√©ment plusieurs clusters Kubernetes
‚úÖ Comprendre le rolling upgrade zero-downtime
‚úÖ Observer le drain/upgrade/rejoin automatis√©
‚úÖ Rollback en cas de probl√®me
‚úÖ Monitorer l'upgrade en temps r√©el
‚úÖ V√©rifier la sant√© post-upgrade
‚úÖ Patterns production pour 100+ clusters

---

**Module 06 compl√©t√© ! üéâ**
**Temps √©coul√© :** 105/120 minutes (10+15+15+15+20+15+15)
**Prochaine √©tape :** Module 07 - Operations & Cleanup
